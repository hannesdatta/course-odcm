{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444e5ee4",
   "metadata": {},
   "source": [
    "# API Advanced using OpenAI's API \n",
    "\n",
    "In this tutorial, we‚Äôll gradually explore how to use **OpenAI‚Äôs API** in Python.\n",
    "Each section builds on the previous one:\n",
    "\n",
    "1. Getting started ‚Äì setting up and sending your first message  \n",
    "2. Basic uses of chat completions  \n",
    "3. Additional endpoints (images, audio, speech-to-text)  \n",
    "4. Embeddings and semantic similarity\n",
    "\n",
    "Every section ends with a short **exercise** so that you can experiment with\n",
    "your own prompts and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9f89",
   "metadata": {},
   "source": [
    "# 1. Getting Started\n",
    "\n",
    "Let‚Äôs begin by setting up access to the API and making our very first request.\n",
    "Think of this as opening a conversation with the ‚ÄúAI waiter‚Äù for the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c03ae",
   "metadata": {},
   "source": [
    "## 1.1 Loading your API key\n",
    "\n",
    "The API key is your personal password for talking to OpenAI‚Äôs servers.\n",
    "To keep it safe, we store it in a hidden file called `.env` in the same folder as this notebook.\n",
    "\n",
    "Example of what that file should contain:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX\n",
    "```\n",
    "\n",
    "The code below loads the key from `.env` and prints only the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ea476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "found = find_dotenv(usecwd=True)\n",
    "load_dotenv(found, override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"Found .env at:\", found)\n",
    "print(\"Loaded key starts with:\", api_key[:8], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7797fec",
   "metadata": {},
   "source": [
    "### üß© Exercise 1 ‚Äî Checking your setup\n",
    "\n",
    "- Verify that the path printed above actually points to your own project folder.  \n",
    "- If it shows a different directory (e.g. your user home), move your `.env` file here.  \n",
    "- Try intentionally changing the key to an invalid one and watch the API return an authentication error.  \n",
    "- Then fix it again!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e35ade",
   "metadata": {},
   "source": [
    "## 1.2 Your first chat with the model\n",
    "\n",
    "With the key loaded, we can finally ‚Äúsay hello‚Äù to the model.\n",
    "The OpenAI client handles the communication for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ae4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt = \"Why might studying in Tilburg be a good idea?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(json.dumps(response.model_dump(), indent=2)[:500], \"...\\n\")\n",
    "print(\"üß† Response:\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a252ad",
   "metadata": {},
   "source": [
    "### üß© Exercise 2 ‚Äî Your first modification\n",
    "\n",
    "- Replace the prompt with your own question (for example *‚ÄúWhat makes a good research question?‚Äù*).  \n",
    "- Change the `temperature` value (try `0`, `1`, and `1.5`) and observe how the creativity of the response changes.  \n",
    "- Reflect: what does ‚Äútemperature‚Äù mean for text generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41babe26",
   "metadata": {},
   "source": [
    "# 2. Basic Uses of Chat Completions\n",
    "\n",
    "Once you can send a single message, the next step is learning how to\n",
    "*structure a conversation* or repeat a task for many inputs.\n",
    "We‚Äôll start with a small dataset of restaurant reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    {\"review\": \"The pasta was perfectly al dente, but the service felt rushed.\"},\n",
    "    {\"review\": \"A cozy spot with incredible sushi and a relaxed atmosphere.\"},\n",
    "    {\"review\": \"Overpriced for the portion size, though the flavors were outstanding.\"},\n",
    "    {\"review\": \"The waiter remembered our names and made the evening feel special.\"},\n",
    "    {\"review\": \"The burger was juicy, but the fries were soggy and cold.\"}\n",
    "]\n",
    "\n",
    "for i, item in enumerate(reviews, 1):\n",
    "    print(f\"{i}. {item['review']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd3981",
   "metadata": {},
   "source": [
    "- Each element here is a small dictionary (key ‚Üí value pair).  \n",
    "- This mirrors the structure of JSON data returned by APIs ‚Äî which is why\n",
    "we practice reading and writing lists of dictionaries instead of spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d98590",
   "metadata": {},
   "source": [
    "## 2.1 Asking the model to analyse many texts\n",
    "\n",
    "We‚Äôll now send each review to the API and ask for a quick sentiment score\n",
    "between 1 (very negative) and 5 (very positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e652aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "prompt_template = (\n",
    "    \"Rate the emotional tone of this restaurant review from 1 (very negative) \"\n",
    "    \"to 5 (very positive). Return only the number.\\nReview: {}\"\n",
    ")\n",
    "\n",
    "for i, item in enumerate(reviews, 1):\n",
    "    question = prompt_template.format(item['review'])\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        temperature=0\n",
    "    )\n",
    "    item[\"score\"] = response.choices[0].message.content.strip()\n",
    "    print(f\"{i}. {item['score']}\")\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9acea",
   "metadata": {},
   "source": [
    "### üß© Exercise 3 ‚Äî Experimenting with prompts\n",
    "\n",
    "- Change the question so that the model returns both a **score and one-sentence explanation**.  \n",
    "- What happens if you set `temperature=1`?  \n",
    "- Try writing a version that asks the model to output `\"positive\"`, `\"neutral\"`, or `\"negative\"` instead of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ae4a2",
   "metadata": {},
   "source": [
    "## 2.2 Does the model remember?\n",
    "\n",
    "Each API call is independent ‚Äî the model does *not* remember previous messages unless you send them again.\n",
    "Let‚Äôs see that in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f15983",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"My favourite colour is blue.\"}],\n",
    "    temperature=0\n",
    ")\n",
    "print(\"First answer:\", r1.choices[0].message.content, \"\\n\")\n",
    "\n",
    "r2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is my favourite colour?\"}],\n",
    "    temperature=0\n",
    ")\n",
    "print(\"Second answer:\", r2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f93875",
   "metadata": {},
   "source": [
    "### üß© Exercise 4 ‚Äî Building a short conversation\n",
    "\n",
    "- Modify the code so that the **second request includes both messages** in its `messages` list.  \n",
    "- Observe how the answer changes when the model has access to the conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66c432",
   "metadata": {},
   "source": [
    "# 3. Additional Endpoints ‚Äî ‚ÄúDifferent Sections of the Menu‚Äù\n",
    "\n",
    "The Chat Completion endpoint is just one of several that OpenAI provides.\n",
    "Others let you generate images, convert text ‚Üí speech, or speech ‚Üí text.\n",
    "Think of these as talking to different *departments* of the same restaurant:\n",
    "the kitchen, the bar, and the cashier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1c737",
   "metadata": {},
   "source": [
    "## 3.1 Generating an image\n",
    "\n",
    "Here we create simple product images by sending text descriptions to the image endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce324d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, base64\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "output_dir = \"product_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "prompts = [\n",
    "    \"A studio photo of a can of sparkling water ‚Äî blue packaging with silver logo\",\n",
    "    \"A studio photo of a can of sparkling water ‚Äî green packaging with lemon slice\"\n",
    "]\n",
    "\n",
    "for i, p in enumerate(prompts, 1):\n",
    "    print(f\"Creating image {i} ...\")\n",
    "    data = {\"model\": \"gpt-image-1\", \"prompt\": p, \"size\": \"512x512\", \"n\": 1}\n",
    "    r = requests.post(\"https://api.openai.com/v1/images/generations\", headers=headers, json=data)\n",
    "    img_b64 = r.json()[\"data\"][0][\"b64_json\"]\n",
    "    file = f\"{output_dir}/variant_{i}.png\"\n",
    "    with open(file, \"wb\") as f:\n",
    "        f.write(base64.b64decode(img_b64))\n",
    "    print(\"Saved:\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652f778",
   "metadata": {},
   "source": [
    "### üß© Exercise 5 ‚Äî Your own product idea\n",
    "\n",
    "- Replace one of the prompts with a description of your favourite drink or snack.  \n",
    "- Change the `size` from `\"512x512\"` to `\"1024x1024\"`.  \n",
    "- Observe how changing the text description changes the generated image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f80254",
   "metadata": {},
   "source": [
    "## 3.2 Text-to-Speech and Transcription\n",
    "\n",
    "Let‚Äôs make the model speak, then turn the audio back into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = [\"nova\", \"shimmer\"]\n",
    "text_input = \"This is a demonstration of OpenAI's text-to-speech model.\"\n",
    "audio_dir = \"audio\"\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "for v in voices:\n",
    "    filename = f\"{audio_dir}/speech_{v}.mp3\"\n",
    "    resp = requests.post(\n",
    "        \"https://api.openai.com/v1/audio/speech\",\n",
    "        headers=headers,\n",
    "        json={\"model\": \"gpt-4o-mini-tts\", \"voice\": v, \"input\": text_input}\n",
    "    )\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    print(\"Saved voice:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ffd6b",
   "metadata": {},
   "source": [
    "Now we transcribe one of those files back into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a8b66",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "audio_file = f\"{audio_dir}/speech_nova.mp3\"\n",
    "with open(audio_file, \"rb\") as f:\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/audio/transcriptions\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "        files={\"file\": (audio_file, f, \"audio/mpeg\")},\n",
    "        data={\"model\": \"whisper-1\"}\n",
    "    )\n",
    "print(\"Transcript:\\n\", r.json().get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cadf1",
   "metadata": {},
   "source": [
    "### üß© Exercise 6 ‚Äî Make it your own\n",
    "\n",
    "- Change `text_input` to a sentence of your choice (for instance a Dutch phrase).  \n",
    "- Try another `voice` name.  \n",
    "- Then transcribe it back ‚Äî does the model handle the language correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396af29",
   "metadata": {},
   "source": [
    "# 4. Embeddings ‚Äî Understanding Similarity\n",
    "\n",
    "While chat and image endpoints produce *content*, embeddings represent *meaning* as numbers.\n",
    "They allow us to measure how similar two pieces of text are, even if they use different words.\n",
    "This section shows two simple applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1efaad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/embeddings\",\n",
    "        headers=headers,\n",
    "        json={\"model\": \"text-embedding-3-small\", \"input\": text}\n",
    "    )\n",
    "    return r.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def cosine(a, b):\n",
    "    dot = sum(x*y for x, y in zip(a, b))\n",
    "    mag = (sum(x*x for x in a)**0.5) * (sum(y*y for y in b)**0.5)\n",
    "    return dot / mag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c6aec",
   "metadata": {},
   "source": [
    "## 4.1 Application 1 ‚Äì Semantic Search\n",
    "\n",
    "Suppose we have a few product descriptions and a user query.\n",
    "We‚Äôll embed both and sort by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"desc\": \"Crispy organic chips with sea salt\"},\n",
    "    {\"desc\": \"High-protein energy bar\"},\n",
    "    {\"desc\": \"Low-fat yogurt with real fruit\"}\n",
    "]\n",
    "\n",
    "for p in products:\n",
    "    p[\"embedding\"] = get_embedding(p[\"desc\"])\n",
    "\n",
    "query = \"healthy breakfast snack\"\n",
    "query_emb = get_embedding(query)\n",
    "\n",
    "for p in products:\n",
    "    p[\"similarity\"] = cosine(p[\"embedding\"], query_emb)\n",
    "\n",
    "products.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "for p in products:\n",
    "    print(p[\"desc\"], \"‚Üí\", round(p[\"similarity\"], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c2e9b",
   "metadata": {},
   "source": [
    "### üß© Exercise 7 ‚Äî New products\n",
    "\n",
    "- Add one more description to the `products` list.  \n",
    "- Try a new `query` such as *‚Äúsweet dessert‚Äù* or *‚Äúpost-workout snack‚Äù*.  \n",
    "- Which description is most similar?  \n",
    "- Reflect on how embeddings capture *meaning*, not exact wording."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550369b5",
   "metadata": {},
   "source": [
    "## 4.2 Application 2 ‚Äì Automatic Coding of Survey Responses\n",
    "\n",
    "Instead of hand-coding open answers, we can embed both responses and category descriptions and match them by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [\n",
    "    {\"text\": \"I love how convenient the app is.\"},\n",
    "    {\"text\": \"It‚Äôs too expensive for what you get.\"},\n",
    "    {\"text\": \"Customer service was very friendly.\"}\n",
    "]\n",
    "\n",
    "themes = [\n",
    "    {\"theme\": \"Convenience\", \"desc\": \"Ease and simplicity of using the product.\"},\n",
    "    {\"theme\": \"Price\", \"desc\": \"Affordability and value for money.\"},\n",
    "    {\"theme\": \"Service\", \"desc\": \"Friendliness and helpfulness of staff.\"}\n",
    "]\n",
    "\n",
    "for r in responses:\n",
    "    r[\"embedding\"] = get_embedding(r[\"text\"])\n",
    "for t in themes:\n",
    "    t[\"embedding\"] = get_embedding(t[\"desc\"])\n",
    "\n",
    "for r in responses:\n",
    "    best = max(themes, key=lambda t: cosine(r[\"embedding\"], t[\"embedding\"]))\n",
    "    r[\"best_theme\"] = best[\"theme\"]\n",
    "    print(r[\"text\"], \"‚Üí\", r[\"best_theme\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065216e",
   "metadata": {},
   "source": [
    "### üß© Exercise 8 ‚Äî Expanding categories\n",
    "\n",
    "- Add a new theme such as `\"Speed\"` or `\"Design\"`.  \n",
    "- Try new responses in different wording.  \n",
    "- Observe whether the model still assigns them to the correct theme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc11f8a",
   "metadata": {},
   "source": [
    "# 5. Wrapping Up\n",
    "\n",
    "In this tutorial we:\n",
    "\n",
    "- Set up API access with OpenAI\n",
    "- Sent and modified chat prompts  \n",
    "- Used loops to analyse multiple texts  \n",
    "- Generated images and speech  \n",
    "- Created embeddings to measure meaning\n",
    "\n",
    "You now know how to combine these building blocks for your own projects:\n",
    "from chat assistants to recommender systems and data analysis pipelines."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
