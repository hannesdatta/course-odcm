{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444e5ee4",
   "metadata": {},
   "source": [
    "# APIs Advanced (OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9f89",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Welcome to the **API Advanced Tutorial**, introducing you to an advanced API for using AI.\n",
    "\n",
    "In this session, we'll start with a brief introduction to APIs and go over some essential programming tools. We'll use a simple analogy to help explain how different models in the OpenAI API work, and we'll carry that analogy throughout the workshop.\n",
    "\n",
    "You'll learn the building blocks for using generative AI in research. We'll also cover important topics like data privacy and security when working with AI tools.\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "- Create an OpenAI account and set up your API key\n",
    "- Understand how to send and receive requests using the OpenAI API\n",
    "- Use different models such as text generation-, speech-, and embeddings models\n",
    "- Be aware of costs, limitations, and ethical considerations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c03ae",
   "metadata": {},
   "source": [
    "## 1. Getting Started\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "\n",
    "Before joining the workshop, make sure you have the following ready:\n",
    "\n",
    "- An [OpenAI account](https://platform.openai.com/signup)\n",
    "  - Note that during class, you will be provided with an API key.\n",
    "  - Outside of the class, you need your own (paid) API key.\n",
    "- A code editor installed on your computer\n",
    "  - e.g., Visual Studio Code (VS Code) ([Install guide via Tilburg Science Hub](https://tilburgsciencehub.com/topics/Computer-Setup/software-installation/IDE/vscode/))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7797fec",
   "metadata": {},
   "source": [
    "### What were API calls again?\n",
    "\n",
    "We'll start with the most basic way to make an API call to OpenAI's GPT model.\n",
    "\n",
    "**Restaurant analogy**:\n",
    "- **You (Customer):** The person making the request  \n",
    "- **OpenAI API (Waiter):** The messenger that takes your request to the AI  \n",
    "- **GPT Model (Chef):** The system that processes your request and creates the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e35ade",
   "metadata": {},
   "source": [
    "### Setting Up Your API Key\n",
    "\n",
    "Before making your first API call, follow these steps:\n",
    "\n",
    "1. Get your API key at [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n",
    "2. Store it securely in an `.env` file\n",
    "   \n",
    "   `OPENAI_API_KEY=\"sk-...\"` \n",
    "   \n",
    "3. In Python, you‚Äôll access it using...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ae4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .env at: /Users/hannesdatta/research/course-odcm/material/tutorials/apis-openai/.env\n",
      "OPENAI_API_KEY = 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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "found = find_dotenv(usecwd=True)\n",
    "print(\"Found .env at:\", found)\n",
    "load_dotenv(found, override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"OPENAI_API_KEY = {api_key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a252ad",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "- Please create a `.env` file in your project directory and try running the code snippet in the cell above. Does it display the correct API key, as shared with you during the class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41babe26",
   "metadata": {},
   "source": [
    "### Let's run our first API call to OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd3981",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- Run the cell below - do you get the output (let's compare it with other students)\n",
    "- Change the *temperature parameter* (e.g., to 1, 2, etc.) - compare the output again. What does *temperature* in the context of AI mean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e652aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Response from the AI (Chef):\n",
      "\n",
      "Studying in Tilburg can be a rewarding experience for several reasons:\n",
      "\n",
      "1. **Quality Education**: Tilburg University is renowned for its high-quality education and research, particularly in social sciences, law, economics, and business administration. It consistently ranks well in both national and international assessments.\n",
      "\n",
      "2. **International Environment**: Tilburg has a diverse student population, with many international students. This multicultural environment fosters a broad exchange of ideas and perspectives, enhancing the learning experience.\n",
      "\n",
      "3. **Strong Academic Focus**: The university emphasizes academic rigor and research, encouraging students to engage critically with their subjects and develop strong analytical skills.\n",
      "\n",
      "4. **Networking Opportunities**: Tilburg is home to various businesses and institutions, providing students with ample networking opportunities through internships, workshops, and collaborations.\n",
      "\n",
      "5. **Student Life**: The city itself is vibrant and student-friendly, offering various cultural, recreational, and social activities. There's an active student community with numerous associations and clubs.\n",
      "\n",
      "6. **Affordable Living**: Compared to larger cities in the Netherlands, Tilburg generally offers lower living costs, making it a more affordable option for students.\n",
      "\n",
      "7. **Strategic Location**: Tilburg is centrally located in the Netherlands, making it easy to travel to other major cities like Amsterdam, Utrecht, and Eindhoven, as well as neighboring countries.\n",
      "\n",
      "8. **Support Services**: The university provides a range of support services for international students, including orientation programs, counseling, and language support, helping students adjust to their new environment.\n",
      "\n",
      "In conclusion, Tilburg combines quality education, a welcoming environment, and numerous opportunities for personal and professional growth, making it an attractive choice for students.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "found = find_dotenv(usecwd=True)\n",
    "load_dotenv(found, override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt = \"Why do you think it is a good idea to study in Tilburg?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "print(\"üß† Response from the AI (Chef):\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9acea",
   "metadata": {},
   "source": [
    "## 2. Applying Basic Programming Principles to OpenAI's API\n",
    "\n",
    "### Looping ‚Äî ‚ÄúOrdering Again and Again‚Äù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f15983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend we're asking the AI to text-analyze review 1: The pasta was perfectly al dente, but the service felt rushed.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 2: A cozy spot with incredible sushi and a relaxed atmosphere.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 3: Overpriced for the portion size, though the flavors were outstanding.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 4: The waiter remembered our names and made the evening feel special.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 5: The burger was juicy, but the fries were soggy and cold.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.DataFrame({\n",
    "    \"review\": [\n",
    "        \"The pasta was perfectly al dente, but the service felt rushed.\",\n",
    "        \"A cozy spot with incredible sushi and a relaxed atmosphere.\",\n",
    "        \"Overpriced for the portion size, though the flavors were outstanding.\",\n",
    "        \"The waiter remembered our names and made the evening feel special.\",\n",
    "        \"The burger was juicy, but the fries were soggy and cold.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "for i, r in enumerate(reviews[\"review\"], 1):\n",
    "    print(f\"Pretend we're asking the AI to text-analyze review {i}: {r}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f93875",
   "metadata": {},
   "source": [
    "### Looping the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ce324d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1...\n",
      "Iteration 2...\n",
      "Iteration 3...\n",
      "Iteration 4...\n",
      "Iteration 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>emotional_score_gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The pasta was perfectly al dente, but the serv...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A cozy spot with incredible sushi and a relaxe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overpriced for the portion size, though the fl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The waiter remembered our names and made the e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The burger was juicy, but the fries were soggy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review emotional_score_gpt\n",
       "0  The pasta was perfectly al dente, but the serv...                   3\n",
       "1  A cozy spot with incredible sushi and a relaxe...                   5\n",
       "2  Overpriced for the portion size, though the fl...                   3\n",
       "3  The waiter remembered our names and made the e...                   5\n",
       "4  The burger was juicy, but the fries were soggy...                   3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "reviews[\"emotional_score_gpt\"] = None\n",
    "prompt_template = (\n",
    "    \"Read the following restaurant review and rate the overall emotional tone \"\n",
    "    \"on a scale from 1 (very negative) to 5 (very positive). Return only the number.\\nReview: {}\"\n",
    ")\n",
    "\n",
    "for i, review_text in enumerate(reviews[\"review\"], 1):\n",
    "    print(f\"Iteration {i}...\")\n",
    "    review_prompt = prompt_template.format(review_text)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": review_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    reviews.loc[i - 1, \"emotional_score_gpt\"] = response.choices[0].message.content\n",
    "    time.sleep(0.5)\n",
    "\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652f778",
   "metadata": {},
   "source": [
    "### API ‚ÄúMemory‚Äù Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c81a36a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response:\n",
      " That's great! Blue is often associated with calmness, tranquility, and stability. Do you have a specific shade of blue that you like the most? \n",
      "\n",
      "Second response (no memory):\n",
      " I don't have access to personal information about you, so I can't know your favorite color. However, if you tell me what it is, I'd be happy to chat about it! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"My favorite color is blue.\"}],\n",
    "    temperature=0\n",
    ")\n",
    "print(\"First response:\\n\", response1.choices[0].message.content, \"\\n\")\n",
    "\n",
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is my favorite color?\"}],\n",
    "    temperature=0\n",
    ")\n",
    "print(\"Second response (no memory):\\n\", response2.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ffd6b",
   "metadata": {},
   "source": [
    "## 3. Meet Some of OpenAI's Endpoints ‚Äî ‚ÄúDifferent Sections of the Menu‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a8b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü™Ñ Generating variant 1...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     21\u001b[39m resp = requests.post(\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1/images/generations\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     headers={\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     24\u001b[39m     json={\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgpt-image-1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m400x400\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m}\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m res = resp.json()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m img_data = \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mb64_json\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     28\u001b[39m image_file = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/product_variant_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(image_file, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mKeyError\u001b[39m: 'data'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "output_dir = \"product_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "base_prompt = (\n",
    "    \"A studio photo of a can of sparkling water, on a minimalist background, \"\n",
    "    \"professional lighting, high-quality product photography, marketing style\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    f\"{base_prompt} ‚Äî blue packaging with silver logo\",\n",
    "    f\"{base_prompt} ‚Äî green packaging with a lemon slice\",\n",
    "    f\"{base_prompt} ‚Äî pink packaging with a berry illustration\"\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"\\nü™Ñ Generating variant {i}...\")\n",
    "    resp = requests.post(\n",
    "        \"https://api.openai.com/v1/images/generations\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"},\n",
    "        json={\"model\": \"gpt-image-1\", \"prompt\": prompt, \"size\": \"1024x1024\", \"n\": 1}\n",
    "    )\n",
    "    res = resp.json()\n",
    "    img_data = res[\"data\"][0][\"b64_json\"]\n",
    "    image_file = f\"{output_dir}/product_variant_{i}.png\"\n",
    "    with open(image_file, \"wb\") as f:\n",
    "        f.write(base64.b64decode(img_data))\n",
    "    print(f\"‚úÖ Saved generated image: {image_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cadf1",
   "metadata": {},
   "source": [
    "### Speech Endpoint ‚Äî Text to Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1efaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved speech to: audio/speech_echo.mp3\n",
      "Saved speech to: audio/speech_nova.mp3\n",
      "Saved speech to: audio/speech_shimmer.mp3\n"
     ]
    }
   ],
   "source": [
    "voices = [\"echo\", \"nova\", \"shimmer\"]\n",
    "input_text = (\n",
    "    \"Today, we are testing the OpenAI API. \"\n",
    "    \"At the moment, we are testing the audio API.\"\n",
    ")\n",
    "audio_dir = \"audio\"\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "for voice in voices:\n",
    "    speech_file = f\"{audio_dir}/speech_{voice}.mp3\"\n",
    "    resp = requests.post(\n",
    "        \"https://api.openai.com/v1/audio/speech\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"},\n",
    "        json={\"model\": \"gpt-4o-mini-tts\", \"voice\": voice, \"input\": input_text}\n",
    "    )\n",
    "    with open(speech_file, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    print(\"Saved speech to:\", speech_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c6aec",
   "metadata": {},
   "source": [
    "### Transcription Endpoint ‚Äî Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = f\"{audio_dir}/speech_echo.mp3\"\n",
    "with open(audio_file_path, \"rb\") as f:\n",
    "    resp = requests.post(\n",
    "        \"https://api.openai.com/v1/audio/transcriptions\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "        files={\"file\": (audio_file_path, f, \"audio/mpeg\")},\n",
    "        data={\"model\": \"whisper-1\"}\n",
    "    )\n",
    "print(\"Transcript:\\n\", resp.json().get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c2e9b",
   "metadata": {},
   "source": [
    "### Embeddings Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The food was delicious and the waiter...\"\n",
    "resp = requests.post(\n",
    "    \"https://api.openai.com/v1/embeddings\",\n",
    "    headers={\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"},\n",
    "    json={\"model\": \"text-embedding-3-small\", \"input\": text}\n",
    ")\n",
    "embedding = resp.json()[\"data\"][0][\"embedding\"]\n",
    "print(\"üî¢ First 50 values of embedding:\\n\", embedding[:50])\n",
    "print(\"\\nThe embedding is a list of\", len(embedding), \"floats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0697f",
   "metadata": {},
   "source": [
    "## Tokens ‚Äî ‚ÄúHow Much You‚Äôre Saying‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain API calls in simple terms, using the customer - waiter - chef metaphor.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "print(\"Output:\\n\", output, \"\\n\")\n",
    "\n",
    "usage = response.usage\n",
    "print(\"Token usage:\")\n",
    "print(\"Input tokens:\", usage.prompt_tokens)\n",
    "print(\"Output tokens:\", usage.completion_tokens)\n",
    "print(\"Total tokens:\", usage.total_tokens)\n",
    "\n",
    "cost = (\n",
    "    (usage.prompt_tokens / 1_000_000) * 2\n",
    "    + (usage.completion_tokens / 1_000_000) * 8\n",
    ")\n",
    "print(\"\\nEstimated cost ($):\", round(cost, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cf46f",
   "metadata": {},
   "source": [
    "## Wrapping Up\n",
    "\n",
    "In this workshop, we covered:\n",
    "- Using your OpenAI API key securely\n",
    "- Making your first API call\n",
    "- Looping over multiple prompts\n",
    "- Using different endpoints (text, image, audio, embeddings)\n",
    "- Understanding tokens and cost"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
