oDCM - Opening Lecture
========================================================
author: Hannes Datta
date:
autosize: true

<style>
.small-code pre code {
  font-size: 1em;
}
</style>

<!--#

https://support.rstudio.com/hc/en-us/articles/200486468
-->

```{r setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(reticulate)
py_install("requests")
py_install("bs4")
```

Welcome to oDCM!
========================================================

We're about to start with the first lecture of this class.

<!--
- If you're joining on Zoom...
- Please **turn on** your camera; it helps us to interact better!
- The **chat** is open - use it like on Twitch/YouTube to also talk to each other (or to me).
-->

If you haven't done so, please 

- **explore the course page** at [https://odcm.hannesdatta.com]().
- login at [http://pulse.tilburg-digital.com]() to explore this week's to do's

<!--

- Drafted this course for a very long time
- Finally got the chance to teaching it now

- While you can find tons of resources online on how to scrape, or how to access data from APIs, none of these tutorials will actually teach you how the way you scrape affects your research. This is the void we will.
- happy to share that vision, and share practical tips

-->


Agenda
========================================================

- Part 1 (08.45 to about 09.45)
  - Getting to know each other
  - Motivation for the course
  - Course framework and learning goals
  - Agenda and practical arrangements
- Break
- Part 2: Python Bootcamp on your laptops (about 10.00 - 11.30)

Disclaimer
========================================================
incremental: true

- This is not a class that merely teaches you Python (but, if you invest time, you'll learn Python on the way!)
- You can also extract web data using other software packages (e.g., R)
- Mix of students at various levels (e.g., beginners, advanced Python users)
- Course is blended; attendance is not mandatory but strongly encouraged
- I will not record any online or offline sessions; slides will be posted always
- Consider me your coach, not your *distant professor*
- Slow me down if you need to

<!--- Streamed sessions Live streams are *complements*, not substitutes for self-study & course website-->

About myself
========================================================
incremental: true

- scraping nerd --- started in 2008 using Visual Basic in Excel
- started doing my own research with scraped and API-extracted data in 2012 (so, 10+ years experience)
- left Germany around your age, now many years in NL
- Associate Professor at Tilburg University

Key areas of expertise
========================================================

- Substantive interests
  - streaming business models (e.g., music, movies)
  - marketing-mix modeling and optimization

- Methodological interests
  - online data collection via APIs and web scraping
  - causal effects with observational data

Teaching activities (all openly available)
========================================================

- MSc Marketing Analytics
    - Data preparation and workflow management (https://dprep.hannesdatta.com)
    - Online data collection and management (https://odcm.hannesdatta.com)
    - MSc Thesis supervision (https://thesis.hannesdatta.com)
- Other initiatives
  - Tilburg Science Hub (https://tilburgsciencehub.com)
  - YouTube channel (https://youtube.com/c/hannesdatta)
  - My code (https://github.com/hannesdatta)
  - More about my work (https://hannesdatta.com)


Getting to know you
========================================================
incremental: true

- What's your background - previous education (e.g., program)?
- Any experience in Python (or other programming languages)?
- What are your passions & talents? (+ why I am asking you this...)


Motivation for course
========================================================

- started out as a PhD student without data
- was interested in music, and found website with data (https://last.fm)
- no best practices in scraping; learnt all by myself and made many mistakes
- scraping undervalued in academic job market, __but__, key role in shaping relevance and rigor of your work
- now scraping and APIs are a large part of what defines me...

Selection of scraping projects I've undertaken
========================================================
incremental: true

- investigate music streaming ([How did music consumption change with Spotify?](https://tiu.nu/spotify))
- [monitored Spotify's user interface and make lists of new releases](https://github.com/hannesdatta/data-spotify-promotions-releases)
- investigate [playlist ecosystem](https://github.com/hannesdatta/data-spotify-playlist-ecosystem) with APIs
- [scraped reviews at Amazon.com](https://journals.sagepub.com/doi/abs/10.1509/jm.11.0560)
- investigating "video streaming wars" (e.g., Netflix versus Disney+, when do consumers use multiple streaming services?), see [trakt.tv]()
- share code [on GitHub](https://github.com/hannesdatta)
- developed a [methodological framework on scraping/APIs](https://doi.org/10.1177%2F00222429221100750) (which we use in this class)
- Faced legal battles...

<!--
- The story about the legal issues you faced (prior to switching to Chartmetric)

- Show example of Chartmetric API output (a website with lots of text)

- Unfortunately, not every websites provides an API
-->

What is scraping, and what are APIs?
========================================================

*With web scraping, you can capture anything you can view in a web browser*

- pricing data at [bol.com](https://bol.com)
- reviews at [Amazon.com](https://amazon.com)
- movie data at [imdb.com](https://imdb.com) or reviews at Rotten Tomatoes

*With APIs, you obtain official data from a firm in a programmatic way*

- e.g., as a developer, interact with Facebook, Instagram, Twitter
- as a researcher, construct data set from analytics firms

Quick web scraper in Python
========================================================
incremental: true
class: small-code

* Let's first import some packages

```{python, eval=TRUE}
import requests
```

* And then call a particular URL (check it out in your browser!)
```{python, eval = TRUE}
url = 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'
book_request = requests.get(url)
```

* Finally, let's retrieve the product title (we use HTML tags for this)

```{python, eval = TRUE}
from bs4 import BeautifulSoup
soup = BeautifulSoup(book_request.text)
print(soup.find('h1'))
```

* Or this...
```{python, eval = TRUE}
print(soup.find('h2'))
```

* Works with any website, even anything you see in a browser (e.g., apps)

Quick APIs in Python
========================================================
class: small-code

* APIs are official interfaces by firms for programmers to extract or submit data, or obtain access to an algorithm

* They work *like* websites (i.e., you can call them with the same snippets as before), but usually you need to pay or at least sign up for the service

```{python, include=FALSE}
# Let's pretend we're a real user
headers = {'authority': 'www.reddit.com', 'cache-control': 'max-age=0', 'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36', 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', 'sec-fetch-site': 'same-origin', 'sec-fetch-mode': 'navigate', 'sec-fetch-user': '?1', 'sec-fetch-dest': 'document', 'accept-language': 'en-GB,en;q=0.9'}
```

```{python, eval = TRUE}
# let's get some data from the skating community
api_request = requests.get('https://www.reddit.com/r/skating/about/.json', headers=headers)
```

* let's structure the output in the JSON format
```{python, eval = TRUE}
api_request.json().get('data').get('subscribers')
```

Opportunities with web data
========================================================
incremental: true

- discover/document novel phenomena (e.g., new platforms/technologies)
- boost relevance for managers (e.g., because of using data *they* care about)
- improving methods (e.g., get data to try out new methods, such as review data & text analysis, images, videos)
- improved inferences (i.e., get more accurate results)

Getting inspired...
========================================================

- *What are cool websites/services you're using often?!*

- *What are important societal issues right now that directly or indirectly affect your lives?*

- *As a marketer, what do you feel will shape our lives in 2-5 years?*

Let's talk about it right now...


<!-- 

bring in post its and put them on a board

-->

Why to care (as a marketer...) (I)
========================================================

![odcm](use_of_webdata.png)

Why to care (as a marketer...) (II)
========================================================

![odcm](citations.png)


Web data versus other marketing data (I)
=============================================

*Why do we need a course on this? Isn't this how research is always done?*

__Yes, but collecting *web data* is different from other datasets!__

- data source selection
  - finding the *right* data source may be difficult as __many__ potential alternatives exist
  - differ in delivery formats (website versus API, compared to CSV/databases)
  - access to data that is *not* available commercially (or that a firm would not like to share)

Web data versus other marketing data (II)
=============================================

- extraction design
  - which information to select (which is available?!)
  - type of variables (sales is rare; review scores are abundant)
  - different stakeholders that could potentially be addressed
  - need to tackle legal and ethical issues

Web data versus other marketing data (III)
=============================================

- collecting data at scale!
  - unprecedent: it's totally automatic (but prone to errors)
  - need to put *monitoring* procedures in place
  - data is not documented, and there is no direct way to ask questions about the data (sampling?! generalizability?)

Each project is totally unique - that's why there is no universal "best way" to approach things...

Methodological Framework
========================================================

![odcm](framework.png)


Learning Goals of this course
========================================================
incremental: true

- **Explain** how to use web data for **creating marketing insight**
- **Select web data sources** and evaluate their value to inform a specific research context or business problem
- **Design the web data collection** while balancing validity, technical feasibility, and exposure to legal/ethical risks
- **Collect data** via web scraping and Application Programming Interfaces (APIs) by mixing, extending, and repurposing code snippets
- **Document and archive collected data** and make it available for public (re)use
- **Track, evaluate, and share progress** on the courseâ€™s learning goals

Welcome to Pulse!
========================================================

- Login at [http://pulse.tilburg-digital.com]() (live demonstration)

![Pulse screenshot](pulse.png)


Positioning in the study program
========================================================

![odcm](odcm_positioning.png)

Course structure and grading
========================================================

- Weekly modules, structured along the methodological framework
  - On-campus lectures and tutorials
  - Self-study
  - Online feedback and coaching sessions
  
- Project in which you put into practice your skills (45% of your grade)

- Online computer exam (50% of your grade)

- Tracking learning process in Pulse (5% of your grade)

- Bonus points available (max .5 on final course grade)

Team project
========================================================

- goals
  - scrape data via web sites or APIs
  - work through the entire method framework
  - receive feedback by students and me (your coach)
  - [project ideas](https://odcm.hannesdatta.com/docs/project/resources/projectideas/) and [past projects](https://odcm.hannesdatta.com/docs/project/resources/pastprojects/)

- evaluation
  - [grading rubric available](https://odcm.hannesdatta.com/docs/project/grading/)
  - self- and peer assessment used

__Please make this a project you can tell friends & family about. Make it matter.__

This year's focus: Retailing
============================

- Goal is to focus on __retailing in its broadest sense__
- Many dimensions
  - online vs. offline
  - "platform" vs. traditional retail
  - categories (say, grocery vs. sport shoes)
  - new vs. used products
  - national vs. international
  - aggregator vs. primary data provider
- Type of data
  - main data (say, sales)
  - meta data (say, product attributes, etc.)

Course website
========================================================

Visit [https://odcm.hannesdatta.com]()!

- It's open education, __so spread the word!__
- Course website is your #1 resource, Canvas only used for
  - posting important announcements,
  - sign up for teams, and
  - submitting data challenges/projects.

- Do all students have access to Canvas?

- Can all students login into [http://pulse.tilburg-digital.com]()?

Common struggles & tips
========================================================

- Take time to become acquainted with the course (e.g., no Canvas but website and Pulse)
- Can be tough at first, but you will gain experience rapidly!
-	It can be overwhelming to follow dPrep and oDCM simultaneously, but the skills you learn are important for your course work, Master Thesis & future career!
-	Easing your start-up pain
  -	Start preparing early on (the first weeks will be the most challenging!)
  -	Have the same group members across dPrep and oDCM
  -	Collaborate with each other and try to help one another, also across teams!
  - Be in touch via WhatsApp, and [install TeamViewer](https://tilburgsciencehub.com/get/teamviewer)

<!--
::: notes

* Exam: Both multiple choice and open questions (you can't pass this course if you don't learn programming  make sure you actively participate in the team project so that you can replicate it individually)
- more specs on exam later

:::
-->

My commitment
========================================================
incremental: true

- Get up to speed with both web scraping and APIs (and know when to pick which one!)
- Learn a bit of Python, __but__, becoming an expert requires years of practice
- Discuss own work and ideas, __but__ requires interaction, talking to me, working hard
- Open software (usable right away, no admin rights required)
- Bring in your own ideas, don't be afraid to study topics off the main stream!
- I value diversity! Be who you want to be. Say what you want to say.

Brain-dead by coding
========================================================

- Coding can be extremely frustrating if you're starting out
- I tend to become semi-"brain-dead" after a day of coding
- Take breaks! Stop coding. Go for a run. Start again.
- You will learn from your mistakes
- Use cheat sheets and our support section

&#8594; quick feedback loops in first few weeks

<!--
::: notes

Mention how we aim to remedy this initial hurdle? (quick feedback loops especially in the first few weeks)

:::
-->

Steps of escalation & getting in touch
========================================================

When you run into trouble, this is your way out!

1. Try to find the info on the course website or Pulse
2. Ask Google and Stackoverflow
3. Ask friend/classmate (form learning groups)
4. Can it wait? Defer to lecturer or feedback sessions.
5. If it can't wait: be in touch with me (--> next slide!)

<!--
::: notes

* Google/Stackoverflow are your best friends
* Live demonstration of how to search on Google and Stackoverflow
* Comment on experiment with live coding sessions (start a call - talk to fellow classmates who're facing the same struggles)


:::
-->

Use of WhatsApp
========================================================

- Please use WhatsApp: +31 13 466 8938.

![WhatsApp](wa_qr.png)

- Let me know your first names!
- Being in touch via email is not so optimal (unless for official matters)


What's in for you?
========================================================

- Essential skills for entrepreneurs
  - e.g., have your own company on the basis of web data and APIs
  - be the linking pin (interface between marketing and analytics)

- Investment in research skills
  - e.g., collect own data & shape its creation to create relevant and rigorous research

- Showcast expertise in coding


Success factors
========================================================

Please tell me __what would make this course a success__ for you

<!--
::: notes

(for me): become more efficient, use Tilburg Science Hub, give me feedback

:::
-->

Next steps
========================================================

- We will continue with our Python bootcamp after a break
- Haven't followed the installation guide? Check it out on the course page now! (tutorials -> software installation)

<!--
- We w
- Install software! (this was required preparation before the course started...)

- Do the Python Bootcamp (after all, you need the know the basics!)

- Learn more about the difference between web scraping and APIs (video)

- Work hard...!

- ...and be in touch on WhatsApp for questions/feedback!
-->

__Any questions so far?!__
