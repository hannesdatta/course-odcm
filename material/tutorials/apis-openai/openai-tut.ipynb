{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444e5ee4",
   "metadata": {},
   "source": [
    "# API Advanced using OpenAI's API \n",
    "\n",
    "In this tutorial, we‚Äôll gradually explore how to use **OpenAI‚Äôs API** in Python.\n",
    "Each section builds on the previous one:\n",
    "\n",
    "1. Getting started ‚Äì setting up and sending your first message  \n",
    "2. Basic uses of chat completions  \n",
    "3. Additional endpoints (images, audio, speech-to-text)  \n",
    "4. Embeddings and semantic similarity\n",
    "\n",
    "Every section ends with a short **exercise** so that you can experiment with\n",
    "your own prompts and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9f89",
   "metadata": {},
   "source": [
    "# 1. Getting Started\n",
    "\n",
    "Let‚Äôs begin by setting up access to the API and making our very first request.\n",
    "Think of this as opening a conversation with the ‚ÄúAI waiter‚Äù for the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c03ae",
   "metadata": {},
   "source": [
    "## 1.1 Loading your API key\n",
    "\n",
    "The API key is your personal password for talking to OpenAI‚Äôs servers.\n",
    "To keep it safe, we store it in a hidden file called `.env` in the same folder as this notebook.\n",
    "\n",
    "Example of what that file should contain:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX\n",
    "```\n",
    "\n",
    "The code below loads the key from `.env` and prints only the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ea476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "found = find_dotenv(usecwd=True)\n",
    "load_dotenv(found, override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"Found .env at:\", found)\n",
    "print(\"Loaded key starts with:\", api_key[:8], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7797fec",
   "metadata": {},
   "source": [
    "### üß© Exercise 1 ‚Äî Checking your setup\n",
    "\n",
    "- Verify that the path printed above actually points to your own project folder.  \n",
    "- If it shows a different directory (e.g. your user home), move your `.env` file here.  \n",
    "- Try intentionally changing the key to an invalid one and watch the API return an authentication error.  \n",
    "- Then fix it again!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e35ade",
   "metadata": {},
   "source": [
    "## 1.2 Your first chat with the model\n",
    "\n",
    "With the key loaded, we can finally ‚Äúsay hello‚Äù to the model.\n",
    "The OpenAI client handles the communication for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ae4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .env at: /Users/hannesdatta/research/course-odcm/material/tutorials/apis-openai/.env\n",
      "OPENAI_API_KEY = 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\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt = \"Why might studying in Tilburg be a good idea?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(json.dumps(response.model_dump(), indent=2)[:500], \"...\\n\")\n",
    "print(\"üß† Response:\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a252ad",
   "metadata": {},
   "source": [
    "### üß© Exercise 2 ‚Äî Your first modification\n",
    "\n",
    "- Replace the prompt with your own question (for example *‚ÄúWhat makes a good research question?‚Äù*).  \n",
    "- Change the `temperature` value (try `0`, `1`, and `1.5`) and observe how the creativity of the response changes.  \n",
    "- Reflect: what does ‚Äútemperature‚Äù mean for text generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41babe26",
   "metadata": {},
   "source": [
    "# 2. Basic Uses of Chat Completions\n",
    "\n",
    "Once you can send a single message, the next step is learning how to\n",
    "*structure a conversation* or repeat a task for many inputs.\n",
    "We‚Äôll start with a small dataset of restaurant reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    {\"review\": \"The pasta was perfectly al dente, but the service felt rushed.\"},\n",
    "    {\"review\": \"A cozy spot with incredible sushi and a relaxed atmosphere.\"},\n",
    "    {\"review\": \"Overpriced for the portion size, though the flavors were outstanding.\"},\n",
    "    {\"review\": \"The waiter remembered our names and made the evening feel special.\"},\n",
    "    {\"review\": \"The burger was juicy, but the fries were soggy and cold.\"}\n",
    "]\n",
    "\n",
    "for i, item in enumerate(reviews, 1):\n",
    "    print(f\"{i}. {item['review']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd3981",
   "metadata": {},
   "source": [
    "- Each element here is a small dictionary (key ‚Üí value pair).  \n",
    "- This mirrors the structure of JSON data returned by APIs ‚Äî which is why\n",
    "we practice reading and writing lists of dictionaries instead of spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d98590",
   "metadata": {},
   "source": [
    "## 2.1 Asking the model to analyse many texts\n",
    "\n",
    "We‚Äôll now send each review to the API and ask for a quick sentiment score\n",
    "between 1 (very negative) and 5 (very positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e652aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Response from the AI (Chef):\n",
      "\n",
      "Studying in Tilburg can be a rewarding experience for several reasons:\n",
      "\n",
      "1. **Quality Education**: Tilburg University is renowned for its high-quality education and research, particularly in social sciences, law, economics, and business administration. It consistently ranks well in both national and international assessments.\n",
      "\n",
      "2. **International Environment**: Tilburg has a diverse student population, with many international students. This multicultural environment fosters a broad exchange of ideas and perspectives, enhancing the learning experience.\n",
      "\n",
      "3. **Strong Academic Focus**: The university emphasizes academic rigor and research, encouraging students to engage critically with their subjects and develop strong analytical skills.\n",
      "\n",
      "4. **Networking Opportunities**: Tilburg is home to various businesses and institutions, providing students with ample networking opportunities through internships, workshops, and collaborations.\n",
      "\n",
      "5. **Student Life**: The city itself is vibrant and student-friendly, offering various cultural, recreational, and social activities. There's an active student community with numerous associations and clubs.\n",
      "\n",
      "6. **Affordable Living**: Compared to larger cities in the Netherlands, Tilburg generally offers lower living costs, making it a more affordable option for students.\n",
      "\n",
      "7. **Strategic Location**: Tilburg is centrally located in the Netherlands, making it easy to travel to other major cities like Amsterdam, Utrecht, and Eindhoven, as well as neighboring countries.\n",
      "\n",
      "8. **Support Services**: The university provides a range of support services for international students, including orientation programs, counseling, and language support, helping students adjust to their new environment.\n",
      "\n",
      "In conclusion, Tilburg combines quality education, a welcoming environment, and numerous opportunities for personal and professional growth, making it an attractive choice for students.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "prompt_template = (\n",
    "    \"Rate the emotional tone of this restaurant review from 1 (very negative) \"\n",
    "    \"to 5 (very positive). Return only the number.\\nReview: {}\"\n",
    ")\n",
    "\n",
    "for i, item in enumerate(reviews, 1):\n",
    "    question = prompt_template.format(item['review'])\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        temperature=0\n",
    "    )\n",
    "    item[\"score\"] = response.choices[0].message.content.strip()\n",
    "    print(f\"{i}. {item['score']}\")\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9acea",
   "metadata": {},
   "source": [
    "### üß© Exercise 3 ‚Äî Experimenting with prompts\n",
    "\n",
    "- Change the question so that the model returns both a **score and one-sentence explanation**.  \n",
    "- What happens if you set `temperature=1`?  \n",
    "- Try writing a version that asks the model to output `\"positive\"`, `\"neutral\"`, or `\"negative\"` instead of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ae4a2",
   "metadata": {},
   "source": [
    "## 2.2 Does the model remember?\n",
    "\n",
    "Each API call is independent ‚Äî the model does *not* remember previous messages unless you send them again.\n",
    "Let‚Äôs see that in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f15983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretend we're asking the AI to text-analyze review 1: The pasta was perfectly al dente, but the service felt rushed.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 2: A cozy spot with incredible sushi and a relaxed atmosphere.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 3: Overpriced for the portion size, though the flavors were outstanding.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 4: The waiter remembered our names and made the evening feel special.\n",
      "\n",
      "Pretend we're asking the AI to text-analyze review 5: The burger was juicy, but the fries were soggy and cold.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"My favourite colour is blue.\"}],\n",
    "    temperature=0\n",
    ")\n",
    "print(\"First answer:\", r1.choices[0].message.content, \"\\n\")\n",
    "\n",
    "r2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is my favourite colour?\"}],\n",
    "    temperature=0\n",
    ")\n",
    "print(\"Second answer:\", r2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f93875",
   "metadata": {},
   "source": [
    "### üß© Exercise 4 ‚Äî Building a short conversation\n",
    "\n",
    "- Modify the code so that the **second request includes both messages** in its `messages` list.  \n",
    "- Observe how the answer changes when the model has access to the conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66c432",
   "metadata": {},
   "source": [
    "# 3. Additional Endpoints ‚Äî ‚ÄúDifferent Sections of the Menu‚Äù\n",
    "\n",
    "The Chat Completion endpoint is just one of several that OpenAI provides.\n",
    "Others let you generate images, convert text ‚Üí speech, or speech ‚Üí text.\n",
    "Think of these as talking to different *departments* of the same restaurant:\n",
    "the kitchen, the bar, and the cashier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1c737",
   "metadata": {},
   "source": [
    "## 3.1 Generating an image\n",
    "\n",
    "Here we create simple product images by sending text descriptions to the image endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ce324d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1...\n",
      "Iteration 2...\n",
      "Iteration 3...\n",
      "Iteration 4...\n",
      "Iteration 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>emotional_score_gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The pasta was perfectly al dente, but the serv...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A cozy spot with incredible sushi and a relaxe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overpriced for the portion size, though the fl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The waiter remembered our names and made the e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The burger was juicy, but the fries were soggy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review emotional_score_gpt\n",
       "0  The pasta was perfectly al dente, but the serv...                   3\n",
       "1  A cozy spot with incredible sushi and a relaxe...                   5\n",
       "2  Overpriced for the portion size, though the fl...                   3\n",
       "3  The waiter remembered our names and made the e...                   5\n",
       "4  The burger was juicy, but the fries were soggy...                   3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, base64\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "output_dir = \"product_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "prompts = [\n",
    "    \"A studio photo of a can of sparkling water ‚Äî blue packaging with silver logo\",\n",
    "    \"A studio photo of a can of sparkling water ‚Äî green packaging with lemon slice\"\n",
    "]\n",
    "\n",
    "for i, p in enumerate(prompts, 1):\n",
    "    print(f\"Creating image {i} ...\")\n",
    "    data = {\"model\": \"gpt-image-1\", \"prompt\": p, \"size\": \"512x512\", \"n\": 1}\n",
    "    r = requests.post(\"https://api.openai.com/v1/images/generations\", headers=headers, json=data)\n",
    "    img_b64 = r.json()[\"data\"][0][\"b64_json\"]\n",
    "    file = f\"{output_dir}/variant_{i}.png\"\n",
    "    with open(file, \"wb\") as f:\n",
    "        f.write(base64.b64decode(img_b64))\n",
    "    print(\"Saved:\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652f778",
   "metadata": {},
   "source": [
    "### üß© Exercise 5 ‚Äî Your own product idea\n",
    "\n",
    "- Replace one of the prompts with a description of your favourite drink or snack.  \n",
    "- Change the `size` from `\"512x512\"` to `\"1024x1024\"`.  \n",
    "- Observe how changing the text description changes the generated image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f80254",
   "metadata": {},
   "source": [
    "## 3.2 Text-to-Speech and Transcription\n",
    "\n",
    "Let‚Äôs make the model speak, then turn the audio back into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c81a36a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response:\n",
      " That's great! Blue is often associated with calmness, tranquility, and stability. Do you have a specific shade of blue that you like the most? \n",
      "\n",
      "Second response (no memory):\n",
      " I don't have access to personal information about you, so I can't know your favorite color. However, if you tell me what it is, I'd be happy to chat about it! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "voices = [\"nova\", \"shimmer\"]\n",
    "text_input = \"This is a demonstration of OpenAI's text-to-speech model.\"\n",
    "audio_dir = \"audio\"\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "for v in voices:\n",
    "    filename = f\"{audio_dir}/speech_{v}.mp3\"\n",
    "    resp = requests.post(\n",
    "        \"https://api.openai.com/v1/audio/speech\",\n",
    "        headers=headers,\n",
    "        json={\"model\": \"gpt-4o-mini-tts\", \"voice\": v, \"input\": text_input}\n",
    "    )\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    print(\"Saved voice:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ffd6b",
   "metadata": {},
   "source": [
    "Now we transcribe one of those files back into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a8b66",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü™Ñ Generating variant 1...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     21\u001b[39m resp = requests.post(\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1/images/generations\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     headers={\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     24\u001b[39m     json={\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgpt-image-1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m400x400\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m}\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m res = resp.json()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m img_data = \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mb64_json\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     28\u001b[39m image_file = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/product_variant_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(image_file, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mKeyError\u001b[39m: 'data'"
     ]
    }
   ],
   "source": [
    "audio_file = f\"{audio_dir}/speech_nova.mp3\"\n",
    "with open(audio_file, \"rb\") as f:\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/audio/transcriptions\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "        files={\"file\": (audio_file, f, \"audio/mpeg\")},\n",
    "        data={\"model\": \"whisper-1\"}\n",
    "    )\n",
    "print(\"Transcript:\\n\", r.json().get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cadf1",
   "metadata": {},
   "source": [
    "### üß© Exercise 6 ‚Äî Make it your own\n",
    "\n",
    "- Change `text_input` to a sentence of your choice (for instance a Dutch phrase).  \n",
    "- Try another `voice` name.  \n",
    "- Then transcribe it back ‚Äî does the model handle the language correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396af29",
   "metadata": {},
   "source": [
    "# 4. Embeddings ‚Äî Understanding Similarity\n",
    "\n",
    "While chat and image endpoints produce *content*, embeddings represent *meaning* as numbers.\n",
    "They allow us to measure how similar two pieces of text are, even if they use different words.\n",
    "This section shows two simple applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1efaad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved speech to: audio/speech_echo.mp3\n",
      "Saved speech to: audio/speech_nova.mp3\n",
      "Saved speech to: audio/speech_shimmer.mp3\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text):\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/embeddings\",\n",
    "        headers=headers,\n",
    "        json={\"model\": \"text-embedding-3-small\", \"input\": text}\n",
    "    )\n",
    "    return r.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def cosine(a, b):\n",
    "    dot = sum(x*y for x, y in zip(a, b))\n",
    "    mag = (sum(x*x for x in a)**0.5) * (sum(y*y for y in b)**0.5)\n",
    "    return dot / mag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c6aec",
   "metadata": {},
   "source": [
    "## 4.1 Application 1 ‚Äì Semantic Search\n",
    "\n",
    "Suppose we have a few product descriptions and a user query.\n",
    "We‚Äôll embed both and sort by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"desc\": \"Crispy organic chips with sea salt\"},\n",
    "    {\"desc\": \"High-protein energy bar\"},\n",
    "    {\"desc\": \"Low-fat yogurt with real fruit\"}\n",
    "]\n",
    "\n",
    "for p in products:\n",
    "    p[\"embedding\"] = get_embedding(p[\"desc\"])\n",
    "\n",
    "query = \"healthy breakfast snack\"\n",
    "query_emb = get_embedding(query)\n",
    "\n",
    "for p in products:\n",
    "    p[\"similarity\"] = cosine(p[\"embedding\"], query_emb)\n",
    "\n",
    "products.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "for p in products:\n",
    "    print(p[\"desc\"], \"‚Üí\", round(p[\"similarity\"], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c2e9b",
   "metadata": {},
   "source": [
    "### üß© Exercise 7 ‚Äî New products\n",
    "\n",
    "- Add one more description to the `products` list.  \n",
    "- Try a new `query` such as *‚Äúsweet dessert‚Äù* or *‚Äúpost-workout snack‚Äù*.  \n",
    "- Which description is most similar?  \n",
    "- Reflect on how embeddings capture *meaning*, not exact wording."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550369b5",
   "metadata": {},
   "source": [
    "## 4.2 Application 2 ‚Äì Automatic Coding of Survey Responses\n",
    "\n",
    "Instead of hand-coding open answers, we can embed both responses and category descriptions and match them by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [\n",
    "    {\"text\": \"I love how convenient the app is.\"},\n",
    "    {\"text\": \"It‚Äôs too expensive for what you get.\"},\n",
    "    {\"text\": \"Customer service was very friendly.\"}\n",
    "]\n",
    "\n",
    "themes = [\n",
    "    {\"theme\": \"Convenience\", \"desc\": \"Ease and simplicity of using the product.\"},\n",
    "    {\"theme\": \"Price\", \"desc\": \"Affordability and value for money.\"},\n",
    "    {\"theme\": \"Service\", \"desc\": \"Friendliness and helpfulness of staff.\"}\n",
    "]\n",
    "\n",
    "for r in responses:\n",
    "    r[\"embedding\"] = get_embedding(r[\"text\"])\n",
    "for t in themes:\n",
    "    t[\"embedding\"] = get_embedding(t[\"desc\"])\n",
    "\n",
    "for r in responses:\n",
    "    best = max(themes, key=lambda t: cosine(r[\"embedding\"], t[\"embedding\"]))\n",
    "    r[\"best_theme\"] = best[\"theme\"]\n",
    "    print(r[\"text\"], \"‚Üí\", r[\"best_theme\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065216e",
   "metadata": {},
   "source": [
    "### üß© Exercise 8 ‚Äî Expanding categories\n",
    "\n",
    "- Add a new theme such as `\"Speed\"` or `\"Design\"`.  \n",
    "- Try new responses in different wording.  \n",
    "- Observe whether the model still assigns them to the correct theme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc11f8a",
   "metadata": {},
   "source": [
    "# 5. Wrapping Up\n",
    "\n",
    "In this tutorial we:\n",
    "\n",
    "- Set up API access with OpenAI\n",
    "- Sent and modified chat prompts  \n",
    "- Used loops to analyse multiple texts  \n",
    "- Generated images and speech  \n",
    "- Created embeddings to measure meaning\n",
    "\n",
    "You now know how to combine these building blocks for your own projects:\n",
    "from chat assistants to recommender systems and data analysis pipelines."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
