<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Hannes Datta">
<meta name="dcterms.date" content="2025-11-20">

<title>Exam preparation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="exam_prep_files/libs/clipboard/clipboard.min.js"></script>
<script src="exam_prep_files/libs/quarto-html/quarto.js"></script>
<script src="exam_prep_files/libs/quarto-html/popper.min.js"></script>
<script src="exam_prep_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="exam_prep_files/libs/quarto-html/anchor.min.js"></script>
<link href="exam_prep_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="exam_prep_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="exam_prep_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="exam_prep_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="exam_prep_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#overview-of-questions" id="toc-overview-of-questions" class="nav-link" data-scroll-target="#overview-of-questions">Overview of Questions</a></li>
  </ul></li>
  <li><a href="#example-questions" id="toc-example-questions" class="nav-link" data-scroll-target="#example-questions">Example Questions</a>
  <ul class="collapse">
  <li><a href="#learning-goal-1" id="toc-learning-goal-1" class="nav-link" data-scroll-target="#learning-goal-1">Learning Goal 1</a>
  <ul class="collapse">
  <li><a href="#exemplary-comprehension-questions-12p" id="toc-exemplary-comprehension-questions-12p" class="nav-link" data-scroll-target="#exemplary-comprehension-questions-12p">Exemplary comprehension questions (12P)</a></li>
  </ul></li>
  <li><a href="#learning-goal-2" id="toc-learning-goal-2" class="nav-link" data-scroll-target="#learning-goal-2">Learning Goal 2</a>
  <ul class="collapse">
  <li><a href="#exemplary-knowledge-questions-multiple-choice-6p" id="toc-exemplary-knowledge-questions-multiple-choice-6p" class="nav-link" data-scroll-target="#exemplary-knowledge-questions-multiple-choice-6p">Exemplary knowledge questions (multiple choice, 6P)</a></li>
  <li><a href="#exemplary-evaluation-questions-open-question-18p" id="toc-exemplary-evaluation-questions-open-question-18p" class="nav-link" data-scroll-target="#exemplary-evaluation-questions-open-question-18p">Exemplary evaluation questions (open question, 18P)</a></li>
  </ul></li>
  <li><a href="#learning-goal-3" id="toc-learning-goal-3" class="nav-link" data-scroll-target="#learning-goal-3">Learning Goal 3</a>
  <ul class="collapse">
  <li><a href="#exemplary-analysis-questions-multiple-choice-2x-6p" id="toc-exemplary-analysis-questions-multiple-choice-2x-6p" class="nav-link" data-scroll-target="#exemplary-analysis-questions-multiple-choice-2x-6p">Exemplary analysis questions (multiple choice, 2x 6P)</a></li>
  <li><a href="#exemplary-analysis-questions-open-question-12p" id="toc-exemplary-analysis-questions-open-question-12p" class="nav-link" data-scroll-target="#exemplary-analysis-questions-open-question-12p">Exemplary analysis questions (open question, 12P)</a></li>
  </ul></li>
  <li><a href="#learning-goal-4" id="toc-learning-goal-4" class="nav-link" data-scroll-target="#learning-goal-4">Learning Goal 4</a>
  <ul class="collapse">
  <li><a href="#exemplary-application-questions-18p" id="toc-exemplary-application-questions-18p" class="nav-link" data-scroll-target="#exemplary-application-questions-18p">Exemplary application questions (18P)</a></li>
  <li><a href="#exemplary-synthesis-questions-30p" id="toc-exemplary-synthesis-questions-30p" class="nav-link" data-scroll-target="#exemplary-synthesis-questions-30p">Exemplary synthesis questions (30P)</a></li>
  </ul></li>
  <li><a href="#learning-goal-5" id="toc-learning-goal-5" class="nav-link" data-scroll-target="#learning-goal-5">Learning Goal 5</a>
  <ul class="collapse">
  <li><a href="#exemplary-knowledge-questions-multiple-choice-12p" id="toc-exemplary-knowledge-questions-multiple-choice-12p" class="nav-link" data-scroll-target="#exemplary-knowledge-questions-multiple-choice-12p">Exemplary knowledge questions (multiple choice, 12P)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#preparing-for-the-exam" id="toc-preparing-for-the-exam" class="nav-link" data-scroll-target="#preparing-for-the-exam">Preparing for the exam</a>
  <ul class="collapse">
  <li><a href="#cheatsheets" id="toc-cheatsheets" class="nav-link" data-scroll-target="#cheatsheets">Cheatsheets</a></li>
  <li><a href="#ideas-for-developing-your-proficiency" id="toc-ideas-for-developing-your-proficiency" class="nav-link" data-scroll-target="#ideas-for-developing-your-proficiency">Ideas for developing your proficiency</a></li>
  <li><a href="#familiarize-yourself-with-testvision" id="toc-familiarize-yourself-with-testvision" class="nav-link" data-scroll-target="#familiarize-yourself-with-testvision">Familiarize yourself with TestVision</a></li>
  <li><a href="#testvisions-introduction-page" id="toc-testvisions-introduction-page" class="nav-link" data-scroll-target="#testvisions-introduction-page">TestVision’s Introduction Page</a></li>
  <li><a href="#technical-tips-beyond" id="toc-technical-tips-beyond" class="nav-link" data-scroll-target="#technical-tips-beyond">Technical Tips &amp; Beyond</a></li>
  </ul></li>
  <li><a href="#inspection" id="toc-inspection" class="nav-link" data-scroll-target="#inspection">Inspection</a>
  <ul class="collapse">
  <li><a href="#logging-in" id="toc-logging-in" class="nav-link" data-scroll-target="#logging-in">Logging in</a></li>
  <li><a href="#inspect-your-exam" id="toc-inspect-your-exam" class="nav-link" data-scroll-target="#inspect-your-exam">Inspect your exam</a>
  <ul class="collapse">
  <li><a href="#get-an-overview-of-the-points-obtained" id="toc-get-an-overview-of-the-points-obtained" class="nav-link" data-scroll-target="#get-an-overview-of-the-points-obtained">1) Get an overview of the points obtained</a></li>
  <li><a href="#review-each-question" id="toc-review-each-question" class="nav-link" data-scroll-target="#review-each-question">2) Review each question</a></li>
  <li><a href="#ask-questions" id="toc-ask-questions" class="nav-link" data-scroll-target="#ask-questions">3) Ask questions</a></li>
  <li><a href="#file-a-written-request-for-review" id="toc-file-a-written-request-for-review" class="nav-link" data-scroll-target="#file-a-written-request-for-review">4) File a written request for review</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Exam preparation</h1>
<p class="subtitle lead">Online Data Collection &amp; Management (328060-M-6)</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Hannes Datta </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 20, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-warning callout-titled" title="Watch Out for Updates">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Watch Out for Updates
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Please note that this is the first draft for the example questions; updates may be posted on Canvas.</li>
<li>Updated will always accompanied by Canvas Announcements.</li>
</ul>
</div>
</div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<ul>
<li>The exam consists of <strong>open and closed (multiple-choice, ranking, matching) questions</strong>, structured along the learning goals of this course.</li>
<li>Cognitive skills that will be tested are knowledge, comprehension, analysis, application, synthesis and evaluation.</li>
<li>You can expect to work two hours on the exam.</li>
<li>Material covered: all readings, lectures (&amp; recordings), tutorials (Jupypter Notebooks, recordings, slides) and code snippets posted to Canvas.</li>
</ul>
<section id="overview-of-questions" class="level2">
<h2 class="anchored" data-anchor-id="overview-of-questions">Overview of Questions</h2>
<p>The table below outlines the types of questions you can expect, along with their sources for each learning goal of the course.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>No.</th>
<th>Learning goal</th>
<th>Evaluation Level</th>
<th>Question Type</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Explain use of web data in academic literature</td>
<td>Comprehension</td>
<td>MC</td>
<td>12</td>
</tr>
<tr class="even">
<td>2</td>
<td>Select web data sources and evaluate academic/business value</td>
<td>Knowledge &amp; Eval.</td>
<td>MC &amp; Open</td>
<td>24</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Design web data collection balancing validity, technical feasibility and legal/ethical risks</td>
<td>Analysis</td>
<td>MC &amp; Open</td>
<td>24</td>
</tr>
<tr class="even">
<td>4</td>
<td>Collect data via web scraping and APIs</td>
<td>Applic. &amp; Synthesis</td>
<td>Coding</td>
<td>48</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Document and archive collected data for public (re)use</td>
<td>Knowledge</td>
<td>MC</td>
<td>12</td>
</tr>
<tr class="even">
<td></td>
<td>Total</td>
<td></td>
<td></td>
<td>120</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="example-questions" class="level1">
<h1>Example Questions</h1>
<p>This section provides example questions, organized by the learning goals of the course. Supporting materials (e.g., datasets or zip files for practice) can be downloaded via the provided links in each subsection. During the exam, such downloads will be made available directly in TestVision (e.g., on the introduction page of the exam, or within specific questions).</p>
<section id="learning-goal-1" class="level2">
<h2 class="anchored" data-anchor-id="learning-goal-1">Learning Goal 1</h2>
<p><em>Explain how web data has been used in the academic marketing literature</em></p>
<section id="exemplary-comprehension-questions-12p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-comprehension-questions-12p">Exemplary comprehension questions (12P)</h3>
<section id="q1.1.1-3p" class="level4">
<h4 class="anchored" data-anchor-id="q1.1.1-3p">Q1.1.1 (3P)</h4>
<p>According to “Fields of Gold: Scraping Web Data for Marketing Insights,” web scraping and API use are crucial for collecting large-scale consumer sentiment data efficiently.</p>
<ol type="a">
<li>TRUE</li>
<li>FALSE</li>
</ol>
<p><em>Correct answer: a</em></p>
</section>
<section id="q1.1.2-3p" class="level4">
<h4 class="anchored" data-anchor-id="q1.1.2-3p">Q1.1.2 (3P)</h4>
<p>The article “Unlocking the Potential of Web Data for Retailing Research” (Guyt, Datta, and Boegershausen 2024) discusses the use of web data in understanding consumer behaviors. Which area of retail research does it specifically highlight as having benefited from web data analysis?</p>
<ol type="a">
<li>physical store layout optimization</li>
<li>in-store customer service improvement</li>
<li>online consumer reviews and their impact</li>
<li>inventory management of assortments</li>
</ol>
<p><em>Correct answer: c</em></p>
</section>
</section>
</section>
<section id="learning-goal-2" class="level2">
<h2 class="anchored" data-anchor-id="learning-goal-2">Learning Goal 2</h2>
<p><em>Select web data sources and evaluate their value in the context of a specific research question or business problem</em></p>
<section id="exemplary-knowledge-questions-multiple-choice-6p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-knowledge-questions-multiple-choice-6p">Exemplary knowledge questions (multiple choice, 6P)</h3>
<section id="q2.1.1-3p" class="level4">
<h4 class="anchored" data-anchor-id="q2.1.1-3p">Q2.1.1 (3P)</h4>
<p>Imagine you are a researcher investigating the historical claims made by a certain company on its website. You suspect the company might have changed some of its earlier claims. Which tool or website would you use to verify changes made to this website over time? Provide the name in the answer box below.</p>
<p><em>Correct answer: archive.org / wayback machine / The Internet archive</em></p>
</section>
<section id="q2.1.2-3p" class="level4">
<h4 class="anchored" data-anchor-id="q2.1.2-3p">Q2.1.2 (3P)</h4>
<p>You are a researcher considering building a web scraper for a study. Before doing so, it is essential to explore other data collection methods. Which of the following are viable alternatives to web scraping for gathering data? More than one options may be correct.</p>
<ol type="a">
<li>Creating new data manually based on algorithmic observations.</li>
<li>Searching for stable APIs and consulting their documentation.</li>
<li>Emailing website owners and requesting permission to collect their content.</li>
<li>Checking whether the required datasets are already available for direct download.</li>
<li>Asking a colleague to browse websites and manually record the data.</li>
</ol>
<p><em>Correct answer: b and d</em></p>
</section>
</section>
<section id="exemplary-evaluation-questions-open-question-18p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-evaluation-questions-open-question-18p">Exemplary evaluation questions (open question, 18P)</h3>
<section id="q2.2.1-18p" class="level4">
<h4 class="anchored" data-anchor-id="q2.2.1-18p">Q2.2.1 (18P)</h4>
<p>Imagine it is the 1st of August 2024 (unixtime: <code>1722463200</code>), and you are seeking to collect longitudinal data from the API of Chartmetric.com. In particular, you wish to collect data the number of followers of playlists on Spotify for a research project that aims to understand the main demand factors for playlists on the platform. You already have access to a list of IDs that can be used as seeds for this project.</p>
<p>Please consider the API documentation of Chartmetric, available at https://api.chartmetric.com/apidoc/.</p>
<p>Then, answer the following questions.</p>
<ol type="1">
<li>Please select and name an endpoint that would allow you to collect the desired data set. Briefly argue why this endpoint provides the suitable data (50 words max.).</li>
<li>Given the endpoint selected and named in (1), please justify whether you require an archival or a live data collection to collect the desired data (75 words max.)</li>
<li>After a bit of prototyping, you obtain the following JSON object from the API:</li>
</ol>
<pre><code>{"status_code": 401,
 "data" : {"X-RateLimit-Limit": 4,
           "X-RateLimit-Remaining": 0,
           "X-RateLimit-Reset": 1722464200}
}</code></pre>
<ol type="a">
<li>How much time will have to pass before the data collection can proceed?</li>
<li>And how many data points do you expect to gather per hour? (75 words max.)</li>
</ol>
<p>Please provide your answer below, in no more than 200 words. Make use of formatting to indicate which subquestion you are answering.</p>
</section>
</section>
</section>
<section id="learning-goal-3" class="level2">
<h2 class="anchored" data-anchor-id="learning-goal-3">Learning Goal 3</h2>
<p><em>Design the web data collection while balancing validity, technical feasibility and exposure to legal/ethical risks</em></p>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>These question will always ask you to solve problems by applying knowledge, facts, techniques and rules acquired through lectures and tutorials in a different way, in writing and not in programming/coding.</p>
<p>Students can expect two work on two smaller (multiple choice) questions (2x 6P), and one larger question (open, 12P). Questions typically are presenting students with a scenario in which a data extraction design needs to be improved, e.g., by making suggestions on the basis of technically feasible sample sizes (also involving ad-hoc calculations in Excel), an API documentation, or use legal risk mitigation strategies.</p>
</div>
</div>
</div>
<section id="exemplary-analysis-questions-multiple-choice-2x-6p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-analysis-questions-multiple-choice-2x-6p">Exemplary analysis questions (multiple choice, 2x 6P)</h3>
<section id="q3.1.1-6p" class="level4">
<h4 class="anchored" data-anchor-id="q3.1.1-6p">Q3.1.1 (6P)</h4>
<p>Please establish the technical feasibility of a longitudinal data collection at Bol.com’s books category. In particular, you are interested in capturing prices every four hours. Based on your experience, you need 10 seconds per request. Up to 40 books are shown on a category overview page. The book category shows 44,053 books.</p>
<ol type="a">
<li>The collection is not feasible due to the extensive time required, resulting in more than four hours between captures.</li>
<li>Given the detailed time frame, web scraping and APIs need to be used to efficiently gather data without disruption.</li>
<li>The collection is feasible but requires optimization of the request rate to avoid violating the site’s terms of use.</li>
<li>It is technically feasible, as the current setup allows for continuous data collection without exceeding request limits.</li>
</ol>
<p><em>Correct answer: d</em></p>
</section>
<section id="q3.1.2-6p" class="level4">
<h4 class="anchored" data-anchor-id="q3.1.2-6p">Q3.1.2 (6P)</h4>
<p>Consider the use of Amazon’s algorithms that affect data display, such as listing products by popularity on category overview pages. Analyze the potential impact of these algorithms on the internal validity of a research study. Which of the following explanations best illustrates how internal validity might be compromised?</p>
<p>Definition of internal validity: “Internal validity is the extent to which a piece of evidence supports a claim about cause and effect, within the context of a particular study.”</p>
<ol type="a">
<li>It may cause issues with reproducibility since algorithms change frequently.</li>
<li>It may lead to selection bias due to the skewed representation of products.</li>
<li>It may create issues for participants who are unsure of how to navigate the site.</li>
<li>It may introduce confounding variables by altering the variables in this research.</li>
</ol>
<p><em>Correct answer: b</em></p>
<!--

#### Q3.1.2 (6P)

Other design: parsing on the fly


3. Please describe the difference between "parsing on the fly" versus "parsing after the data collection" (according to "Fields of Gold"). (*comprehension*)

#### Q3.1.3 (6P)

Live vs archival web scraper

4. What conclusions can you draw with regard to the accuracy of the timestamps provided in the user review section of metacritic (e.g., https://www.metacritic.com/movie/the-godfather/user-reviews )? Provide a short answer in less than 50 words. (*analysis*)


#### Q3.1.4 (6P)

<!--
2. What is the purpose of `beautifulSoup` in the context of web scraping? (*comprehension*)
-->
</section>
</section>
<section id="exemplary-analysis-questions-open-question-12p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-analysis-questions-open-question-12p">Exemplary analysis questions (open question, 12P)</h3>
<section id="q3.2.1-12p" class="level4">
<h4 class="anchored" data-anchor-id="q3.2.1-12p">Q3.2.1 (12P)</h4>
<p>Identify and discuss two out of the five broad topics that need to be addressed when seeking legal counsel about web data collection. For each of your two selected topics, provide an example and explain how you can address it in a research study. Provide your answer in two paragraphs, format in bold the name of the topic, and use less than 100 words in total.</p>
<!--
#### Q3.2.2 (12P)

Legal risk mitigation 2
-->
</section>
</section>
</section>
<section id="learning-goal-4" class="level2">
<h2 class="anchored" data-anchor-id="learning-goal-4">Learning Goal 4</h2>
<p><em>Collect data via web scraping and Application Programming Interfaces (APIs) by mixing, extending and repurposing code snippets</em></p>
<section id="exemplary-application-questions-18p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-application-questions-18p">Exemplary application questions (18P)</h3>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>This question will always ask you to solve problems in a code snippet related to a web scraping or API-based project by applying acquired knowledge, facts, techniques and rules covered in the tutorials and code files (e.g., Python, Jupyter Notebook) shared on Canvas. Common tasks are related to (a) debugging (i.e., making a code do what it is supposed to be doing), and (b) extending the functionality of code.</p>
</div>
</div>
</div>
<section id="q4.1.1-18p" class="level4">
<h4 class="anchored" data-anchor-id="q4.1.1-18p">Q4.1.1 (18P)</h4>
<p>Please take a look at the code snippet below, which retrieves data on the title and number of comments for posts on the ‘marketing’ subreddit. Please modify the code such that this data is extracted for the ‘digitalmarketing’ and ‘socialmedia’ subreddits, in addition to the ‘marketing’ subreddit. The output should be a list with dictionaries including the subreddit name, title and number of comments for each post.</p>
<p><strong>Starting code snippet</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>headers <span class="op">=</span> {<span class="st">'authority'</span>: <span class="st">'www.reddit.com'</span>, <span class="st">'cache-control'</span>: <span class="st">'max-age=10'</span>, <span class="st">'upgrade-insecure-requests'</span>: <span class="st">'1'</span>, <span class="st">'user-agent'</span>: <span class="st">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'</span>, <span class="st">'accept'</span>: <span class="st">'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'</span>, <span class="st">'sec-fetch-site'</span>: <span class="st">'same-origin'</span>, <span class="st">'sec-fetch-mode'</span>: <span class="st">'navigate'</span>, <span class="st">'sec-fetch-user'</span>: <span class="st">'?1'</span>, <span class="st">'sec-fetch-dest'</span>: <span class="st">'document'</span>, <span class="st">'accept-language'</span>: <span class="st">'en-GB,en;q=0.9'</span>}</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_posts(subreddit):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    url <span class="op">=</span> <span class="ss">f'https://www.reddit.com/r/</span><span class="sc">{</span>subreddit<span class="sc">}</span><span class="ss">.json'</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> requests.get(url,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                            headers<span class="op">=</span>headers)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    json_response <span class="op">=</span> response.json()</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    posts <span class="op">=</span> []</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> json_response[<span class="st">'data'</span>][<span class="st">'children'</span>]:</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        posts.append({<span class="st">'title'</span>: item[<span class="st">'data'</span>][<span class="st">'title'</span>],</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'number of comments:'</span>: item[<span class="st">'data'</span>][<span class="st">'num_comments'</span>]})</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> posts</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>posts <span class="op">=</span> get_users(<span class="st">'marketing'</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>posts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Solution</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>headers <span class="op">=</span> {<span class="st">'authority'</span>: <span class="st">'www.reddit.com'</span>, <span class="st">'cache-control'</span>: <span class="st">'max-age=10'</span>, <span class="st">'upgrade-insecure-requests'</span>: <span class="st">'1'</span>, <span class="st">'user-agent'</span>: <span class="st">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'</span>, <span class="st">'accept'</span>: <span class="st">'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'</span>, <span class="st">'sec-fetch-site'</span>: <span class="st">'same-origin'</span>, <span class="st">'sec-fetch-mode'</span>: <span class="st">'navigate'</span>, <span class="st">'sec-fetch-user'</span>: <span class="st">'?1'</span>, <span class="st">'sec-fetch-dest'</span>: <span class="st">'document'</span>, <span class="st">'accept-language'</span>: <span class="st">'en-GB,en;q=0.9'</span>}</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_posts(subreddit):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    url <span class="op">=</span> <span class="ss">f'https://www.reddit.com/r/</span><span class="sc">{</span>subreddit<span class="sc">}</span><span class="ss">.json'</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> requests.get(url,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>                            headers<span class="op">=</span>headers)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    json_response <span class="op">=</span> response.json()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    posts <span class="op">=</span> []</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> json_response[<span class="st">'data'</span>][<span class="st">'children'</span>]:</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        posts.append({<span class="st">'subreddit name'</span>: item[<span class="st">'data'</span>][<span class="st">'subreddit'</span>],</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'title'</span>: item[<span class="st">'data'</span>][<span class="st">'title'</span>],</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'number of comments:'</span>: item[<span class="st">'data'</span>][<span class="st">'num_comments'</span>]})</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> posts</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>subreddits <span class="op">=</span> [<span class="st">'marketing'</span>, <span class="st">'digitalmarketing'</span>, <span class="st">'socialmedia'</span>]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>all_posts <span class="op">=</span> [] <span class="co"># create empty list to hold final results</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># loop through subreddits</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> sub <span class="kw">in</span> subreddits:</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use `get_users()` function to retrieve post for subreddit `sub`</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    retrieved_posts <span class="op">=</span> get_posts(sub)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop through posts, and add to `posts` list holding all posts as a final result</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> post <span class="kw">in</span> retrieved_posts:</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        all_posts.append(post)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>all_posts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="q4.1.2-18p" class="level4">
<h4 class="anchored" data-anchor-id="q4.1.2-18p">Q4.1.2 (18P)</h4>
<p>Please use Selenium to open https://infinite-scroll.com/demo/full-page/, and scroll down 10 times. As you proceed, store all H2 titles in a new-line separated JSON file (store not only links, but also the iteration number).</p>
<p><strong>Starting code</strong></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium <span class="im">import</span> webdriver</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.chrome.service <span class="im">import</span> Service <span class="im">as</span> ChromeService</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> webdriver_manager.chrome <span class="im">import</span> ChromeDriverManager</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.by <span class="im">import</span> By</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.keys <span class="im">import</span> Keys</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(service<span class="op">=</span>ChromeService(ChromeDriverManager().install()))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://infinite-scroll.com/demo/full-page/"</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>driver.get(url)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">4</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Scroll down the page</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>scroll_pause_time <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):  <span class="co"># Scroll down 3 times</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    driver.execute_script(<span class="st">"window.scrollTo(0, document.body.scrollHeight);"</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    time.sleep(scroll_pause_time)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Solution</strong></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium <span class="im">import</span> webdriver</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.chrome.service <span class="im">import</span> Service <span class="im">as</span> ChromeService</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> webdriver_manager.chrome <span class="im">import</span> ChromeDriverManager</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.by <span class="im">import</span> By</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.keys <span class="im">import</span> Keys</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(service<span class="op">=</span>ChromeService(ChromeDriverManager().install()))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://infinite-scroll.com/demo/full-page/"</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>driver.get(url)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">4</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>f<span class="op">=</span><span class="bu">open</span>(<span class="st">'infinite_scroll.json'</span>,<span class="st">'w'</span>,encoding<span class="op">=</span><span class="st">'utf-8'</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Scroll down the page</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>scroll_pause_time <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):  <span class="co"># Scroll down 10 times</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    driver.execute_script(<span class="st">"window.scrollTo(0, document.body.scrollHeight);"</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(driver.page_source)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> title <span class="kw">in</span> soup.find_all(<span class="st">'h2'</span>):</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        obj<span class="op">=</span>{<span class="st">'title'</span>: title.get_text()}</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        f.write(json.dumps(obj))</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        f.write(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    time.sleep(scroll_pause_time)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>f.close()    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="q4.1.3-18p" class="level4">
<h4 class="anchored" data-anchor-id="q4.1.3-18p">Q4.1.3 (18P)</h4>
<p>Please view the code snippet below, which provides the key building blocks to clicking on buttons with Selenium. Please modify the snippet so that it extracts all key headlines along with their URLs from the New York Times homepage (https://www.nytimes.com/). Since the site has a cookie consent banner, use Selenium to automate clicking the “Accept all” button. Collect your data to a dictionary. Save the data to a JSON file (<code>nytimes_articles.json</code>).</p>
<p><strong>Starter Code:</strong></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium <span class="im">import</span> webdriver</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.chrome.service <span class="im">import</span> Service <span class="im">as</span> ChromeService</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> webdriver_manager.chrome <span class="im">import</span> ChromeDriverManager</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.by <span class="im">import</span> By</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize WebDriver</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(service<span class="op">=</span>ChromeService(ChromeDriverManager().install()))</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Open New York Times homepage</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://www.nytimes.com/"</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>driver.get(url)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">3</span>)  <span class="co"># Wait for page to load</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle cookie banner (Click "Accept all" button)</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    cookie_button <span class="op">=</span> driver.find_element(By.XPATH, <span class="st">'TODO: Add cookie button path here'</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    cookie_button.click()</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cookie banner accepted."</span>)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Allow time for the banner to close</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No cookie banner found or already accepted."</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract article headlines and URLs</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(driver.page_source, <span class="st">'html.parser'</span>)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>articles <span class="op">=</span> []</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">TODO</span><span class="co">: Find all article elements and extract the title and URL</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Save extracted data to a JSON file</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'nytimes_articles.json'</span>, <span class="st">'w'</span>, encoding<span class="op">=</span><span class="st">'utf-8'</span>) <span class="im">as</span> f:</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Write the articles list to the JSON file</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Close WebDriver</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>driver.quit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium <span class="im">import</span> webdriver</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.chrome.service <span class="im">import</span> Service <span class="im">as</span> ChromeService</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> webdriver_manager.chrome <span class="im">import</span> ChromeDriverManager</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> selenium.webdriver.common.by <span class="im">import</span> By</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize WebDriver</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>driver <span class="op">=</span> webdriver.Chrome(service<span class="op">=</span>ChromeService(ChromeDriverManager().install()))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Open NYTimes</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://www.nytimes.com/"</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>driver.get(url)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">3</span>)  </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle cookie banner (Click "Accept all" button)</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    cookie_button <span class="op">=</span> driver.find_element(By.XPATH, <span class="st">'//button[@data-testid="Accept all-btn"]'</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    cookie_button.click()</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cookie banner accepted."</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Allow time for the banner to close</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"No cookie banner found or already accepted."</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract all articles with titles and URLs</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(driver.page_source, <span class="st">'html.parser'</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>articles <span class="op">=</span> []</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> section <span class="kw">in</span> soup.find_all(<span class="st">'section'</span>, class_<span class="op">=</span><span class="st">'story-wrapper'</span>):</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    link <span class="op">=</span> section.find(<span class="st">'a'</span>, class_<span class="op">=</span><span class="st">'css-9mylee'</span>)  <span class="co"># Find the article link</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    title_tag <span class="op">=</span> section.find(<span class="st">'div'</span>, class_<span class="op">=</span><span class="st">'css-xdandi'</span>)  <span class="co"># Find the title container</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> link <span class="kw">and</span> title_tag:</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        article_title <span class="op">=</span> title_tag.get_text(strip<span class="op">=</span><span class="va">True</span>)  <span class="co"># Extract the article title</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        article_url <span class="op">=</span> link[<span class="st">'href'</span>]  <span class="co"># Extract the article URL</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store in dictionary format</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        articles.append({</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">"title"</span>: article_title,</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">"url"</span>: article_url</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Save to JSON</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'nytimes_articles.json'</span>, <span class="st">'w'</span>, encoding<span class="op">=</span><span class="st">'utf-8'</span>) <span class="im">as</span> f:</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    json.dump(articles, f, ensure_ascii<span class="op">=</span><span class="va">False</span>, indent<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st"> Articles saved to 'nytimes_articles.json'"</span>)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Close WebDriver</span></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>driver.quit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="exemplary-synthesis-questions-30p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-synthesis-questions-30p">Exemplary synthesis questions (30P)</h3>
<div class="callout callout-style-simple callout-none no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>This question will always ask you to change or create a code snippet related to a web scraping or API-based project by combining code elements in a new pattern or proposing alternative solutions, based on the content of tutorials and code files (e.g., Python, Jupyter Notebook) shared on Canvas. Common tasks involve larger scraping- or API-based tasks, in which (a) code will be adapted to collect data at scale (e.g., via looping), or (b) create code “from scratch” to perform tasks related to web scraping and APIs (e.g., enrich data via the API of OpenAI).</p>
</div>
</div>
</div>
<section id="q4.2.1-30p" class="level4">
<h4 class="anchored" data-anchor-id="q4.2.1-30p">Q4.2.1 (30P)</h4>
<p>Please collect the product names and prices for all books listed in this section: https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html. Please not only list these variables, but also provide timestamps from the moment that you started your data collection. Submit your (a) Python code (as <code>.py</code> or <code>.ipynb</code>), along with the collected data (<code>.json</code>). Please start from the code snippet below.</p>
<p><strong>Code to start from</strong></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import packages</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># set url</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>page_url <span class="op">=</span> <span class="st">'https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html'</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> requests.get(page_url)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>res.encoding <span class="op">=</span> res.apparent_encoding</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(res.text, <span class="st">"html.parser"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>books <span class="op">=</span> soup.find_all(class_<span class="op">=</span><span class="st">"product_pod"</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> book <span class="kw">in</span> books:</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> book.find(<span class="st">'h3'</span>).get_text() </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Solution</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import packages</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># set url</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>page_url <span class="op">=</span> <span class="st">'https://books.toscrape.com/catalogue/category/books/nonfiction_13/index.html'</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_books(page_url):</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> requests.get(page_url)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    res.encoding <span class="op">=</span> res.apparent_encoding</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(res.text, <span class="st">"html.parser"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    books <span class="op">=</span> soup.find_all(class_<span class="op">=</span><span class="st">"product_pod"</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    time_start <span class="op">=</span> <span class="bu">int</span>(time.time())</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    book_list <span class="op">=</span> []</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> book <span class="kw">in</span> books:</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        name <span class="op">=</span> book.find(<span class="st">'h3'</span>).get_text() </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        price <span class="op">=</span> book.find(<span class="st">'p'</span>, class_<span class="op">=</span><span class="st">'price_color'</span>).get_text()</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        return_dic <span class="op">=</span> {<span class="st">'name'</span>: name,</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'price'</span>: price,</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'time_start'</span>: time_start}</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        book_list.append(return_dic)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(book_list)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="co"># write a function that checks whether there is a next page</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_next_page(url):</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> requests.get(url)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(res.text, <span class="st">"html.parser"</span>)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    next_btn <span class="op">=</span> soup.find(class_<span class="op">=</span> <span class="st">"next"</span>)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> next_btn.find(<span class="st">"a"</span>).attrs[<span class="st">"href"</span>] <span class="cf">if</span> next_btn <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>all_books <span class="op">=</span> []</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> page_url:</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(page_url)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> book <span class="kw">in</span> get_books(page_url):</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>        all_books.append(book)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> check_next_page(page_url) <span class="op">!=</span> <span class="va">None</span>: </span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>        page_url <span class="op">=</span> <span class="st">"https://books.toscrape.com/catalogue/category/books/nonfiction_13/"</span> <span class="op">+</span> check_next_page(page_url)</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>: </span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span> </span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="co"># write to file</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="bu">open</span>(<span class="st">'all_books.json'</span>, <span class="st">'w'</span>)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> book <span class="kw">in</span> all_books:</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    f.write(json.dumps(book)<span class="op">+</span><span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>f.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="q4.2.2-30p" class="level4">
<h4 class="anchored" data-anchor-id="q4.2.2-30p">Q4.2.2 (30P)</h4>
<p>Scrape the top 1000 lifetime grossing movies (domestic) from <a href="https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW">Box Office Mojo</a>. Export the rank, title, lifetime gross and release year of these movies to a CSV file.</p>
<p><strong>Starting code</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import packages</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://www.boxofficemojo.com/chart/top_lifetime_gross/?area=XWW&amp;offset=0'</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> requests.get(url)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>res.encoding <span class="op">=</span> res.apparent_encoding</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(res.text, <span class="st">"html.parser"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>movies <span class="op">=</span> soup.find(class_<span class="op">=</span><span class="st">'imdb-scroll-table'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Solution</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> csv</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>top_1000<span class="op">=</span>[]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    page_url<span class="op">=</span><span class="st">'https://www.boxofficemojo.com/chart/top_lifetime_gross/?offset='</span><span class="op">+</span> <span class="bu">str</span>(i<span class="op">*</span><span class="dv">200</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> requests.get(page_url)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    res.encoding <span class="op">=</span> res.apparent_encoding</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(res.text, <span class="st">"html.parser"</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    movies <span class="op">=</span> soup.find(<span class="st">'table'</span>, class_<span class="op">=</span> <span class="st">'mojo-body-table'</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    j<span class="op">=</span><span class="dv">0</span>  </span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> movie <span class="kw">in</span> movies:</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> j<span class="op">!=</span><span class="dv">0</span>:</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>            ranking<span class="op">=</span> movie.find(<span class="st">'td'</span>, class_<span class="op">=</span><span class="st">'a-text-right'</span>).get_text()</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>            title<span class="op">=</span> movie.find(<span class="st">'a'</span>, class_<span class="op">=</span><span class="st">'a-link-normal'</span>).get_text()</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>            lifetime_gross<span class="op">=</span>movie.find(<span class="st">'td'</span>, class_<span class="op">=</span><span class="st">'mojo-field-type-money'</span>).get_text()</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>            release_year<span class="op">=</span> movie.find(<span class="st">'td'</span>, class_<span class="op">=</span><span class="st">'mojo-field-type-year'</span>).get_text()</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>            top_1000.append({<span class="st">'ranking'</span>:ranking,</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'title'</span>: title,</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'lifetime_gross'</span>: lifetime_gross,</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>                            <span class="st">'release_year'</span>: release_year})</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        j<span class="op">=</span>j<span class="op">+</span><span class="dv">1</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'top_1000movies.csv'</span>, mode<span class="op">=</span><span class="st">'w'</span>, newline<span class="op">=</span><span class="st">''</span>, encoding<span class="op">=</span><span class="st">'utf-8'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>    writer <span class="op">=</span> csv.DictWriter(<span class="bu">file</span>, fieldnames<span class="op">=</span>[<span class="st">'ranking'</span>, <span class="st">'title'</span>, <span class="st">'lifetime_gross'</span>, <span class="st">'release_year'</span>])</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>    writer.writeheader()  </span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    writer.writerows(top_1000)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="q4.2.3-30p" class="level4">
<h4 class="anchored" data-anchor-id="q4.2.3-30p">Q4.2.3 (30P)</h4>
<p>Scrape all category names, (e.g., “academic study applications”), and their corresponding article subcategories (e.g., exam preparation) and links from tilburg.ai (https://tilburg.ai/articles/) using BeautifulSoup. Please extract information on the category names, along with the subcategory names and links listed within them. Save them in <em>one</em> JSON object, stored in <em>one</em> JSON file called <code>tilburg_ai_articles.json</code>.</p>
<p><strong>Starter Code:</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># URL to scrape</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://tilburg.ai/articles/'</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fetch the page content</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(url)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if the request is successful</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(response.content, <span class="st">'html.parser'</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> []</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Find all sections containing subheaders and articles</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Loop through each section, extract subheader and articles</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># </span><span class="al">TODO</span><span class="co">: Save extracted data in JSON file</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Data saved to 'tilburg_ai_articles.json'"</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Failed to retrieve the page. Status code: </span><span class="sc">{</span>response<span class="sc">.</span>status_code<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># URL of the Tilburg.ai Articles page</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">'https://tilburg.ai/articles/'</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Send a GET request to the URL</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> requests.get(url)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if the request was successful</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parse the HTML content of the page</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    soup <span class="op">=</span> BeautifulSoup(response.content, <span class="st">'html.parser'</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize a list to hold the data</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> []</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find all sections that represent subheaders and articles</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    sections <span class="op">=</span> soup.find_all(<span class="st">'section'</span>, class_<span class="op">=</span><span class="st">'menu-section'</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate over each section</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> section <span class="kw">in</span> sections:</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract the subheader (category) name</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        subheader_tag <span class="op">=</span> section.find(<span class="st">'h2'</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> subheader_tag <span class="kw">and</span> subheader_tag.a:</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>            subheader <span class="op">=</span> subheader_tag.a.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Initialize a list to hold articles under this subheader</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>            articles <span class="op">=</span> []</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Find all article links within the section</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>            article_tags <span class="op">=</span> section.find_all(<span class="st">'a'</span>, href<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> article_tag <span class="kw">in</span> article_tags:</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>                article_name <span class="op">=</span> article_tag.get_text(strip<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>                article_url <span class="op">=</span> article_tag[<span class="st">'href'</span>]</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>                articles.append({<span class="st">'name'</span>: article_name, <span class="st">'url'</span>: article_url})</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Append the subheader and its articles to the data list</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>            data.append({<span class="st">'subheader'</span>: subheader, <span class="st">'articles'</span>: articles})</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save the data to a JSON file</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(<span class="st">'tilburg_ai_articles.json'</span>, <span class="st">'w'</span>, encoding<span class="op">=</span><span class="st">'utf-8'</span>) <span class="im">as</span> f:</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>        json.dump(data, f, ensure_ascii<span class="op">=</span><span class="va">False</span>, indent<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Data has been saved to 'tilburg_ai_articles.json'"</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Failed to retrieve the page. Status code: </span><span class="sc">{</span>response<span class="sc">.</span>status_code<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="learning-goal-5" class="level2">
<h2 class="anchored" data-anchor-id="learning-goal-5">Learning Goal 5</h2>
<p><em>Document and archive collected data, and make it available for public (re)use</em></p>
<section id="exemplary-knowledge-questions-multiple-choice-12p" class="level3">
<h3 class="anchored" data-anchor-id="exemplary-knowledge-questions-multiple-choice-12p">Exemplary knowledge questions (multiple choice, 12P)</h3>
<section id="q5.1-3p" class="level4">
<h4 class="anchored" data-anchor-id="q5.1-3p">Q5.1 (3P)</h4>
<p>What is a primary benefit of meticulously maintaining a logbook during a web scraping-based research project?</p>
<ol type="a">
<li>It ensures that the project is completed faster.</li>
<li>It helps trace issues, ensures reproducibility, and facilitates sharing the methodology.</li>
<li>It reduces the need for efficient coding practices.</li>
<li>It prevents the project from becoming cluttered and difficult to understand.</li>
</ol>
<p><em>Correct answer: b</em></p>
</section>
<section id="q5.2-3p" class="level4">
<h4 class="anchored" data-anchor-id="q5.2-3p">Q5.2 (3P)</h4>
<p>What is an important aspect to consider when planning for long-term storage of data collected by a web scraper?</p>
<ol type="a">
<li>Keeping the data on a local computer or external hard drive.</li>
<li>Using cloud storage services, such as Dropbox or Google Drive.</li>
<li>Archiving the data in a recognized data repository, such as re3data.org or Zenodo.</li>
<li>Publishing the data on a personal website or blog.</li>
</ol>
</section>
</section>
</section>
</section>
<section id="preparing-for-the-exam" class="level1">
<h1>Preparing for the exam</h1>
<p>This section provides information that will help you prepare well for the exam.</p>
<section id="cheatsheets" class="level2">
<h2 class="anchored" data-anchor-id="cheatsheets">Cheatsheets</h2>
<ul>
<li>Students will have access to one cheatsheet, <strong>collectively created</strong> on Google Docs, and submitted for review by the course coordinator before the exam.</li>
<li>Ahead of the exam, there will be a short Q&amp;A session where you can ask questions about the cheat sheet (and your ideas) to the instructor.</li>
<li>The cheatsheet will be edited, converted to PDF, and shared with everyone as part of the final set of materials for the exam.</li>
</ul>
</section>
<section id="ideas-for-developing-your-proficiency" class="level2">
<h2 class="anchored" data-anchor-id="ideas-for-developing-your-proficiency">Ideas for developing your proficiency</h2>
<ul>
<li>Please work through the example questions and tutorials. While this has been difficult when you did it for the first time, can you do it on your own now?</li>
<li>We encourage you to generate your own example questions. Just start from a combination of learning goals (e.g., learn how to scrape, “web scraping 101”) and cognitive skill levels (e.g., “evaluation”). Combining these two dimensions will help you come up with a creative way of asking a good example question. See also <a href="https://mygrowthmindsethome.files.wordpress.com/2019/03/blooms-taxonomy.pdf">this summary of Bloom’s Taxonomy</a>, which we also use to generate exam questions.</li>
</ul>
<p>Above all, see this exam preparation <em>not</em> as a way to merely study for the exam, but as a way to further develop and make more accessible your existing skill set.</p>
</section>
<section id="familiarize-yourself-with-testvision" class="level2">
<h2 class="anchored" data-anchor-id="familiarize-yourself-with-testvision">Familiarize yourself with TestVision</h2>
<ul>
<li>Take the “technical practice exam” - a link will be shared on Canvas; after which you will be able to practice downloaded and uploading files.</li>
<li>More practice? TestVision also provides a <a href="https://oefentoetsen.testvision.nl/online/fe/login_ot.htm?campagne=tlb_demo_eng&amp;taal=2">generic practice exam</a></li>
<li>Tilburg University also provides <a href="https://www.tilburguniversity.edu/students/studying/exams/e-assessment/testvision">additional resources about TestVision</a></li>
</ul>
</section>
<section id="testvisions-introduction-page" class="level2">
<h2 class="anchored" data-anchor-id="testvisions-introduction-page">TestVision’s Introduction Page</h2>
<p>Every exam begins with an “introduction” or “cover” page, which contains the official exam instructions. Below, you will find an example of the cover page used in previous years. Please note that the instructions for the actual exam may differ slightly, so it is important to read them carefully.</p>
<p>The exact cover page for this year’s exam will be made available on Canvas in advance, so you will not need to spend time re-reading it when starting your exam. Be sure to review it thoroughly before exam day.</p>
<p><img src="intro_part1.png" class="img-fluid"> <img src="intro_part2.png" class="img-fluid"></p>
</section>
<section id="technical-tips-beyond" class="level2">
<h2 class="anchored" data-anchor-id="technical-tips-beyond">Technical Tips &amp; Beyond</h2>
<ul>
<li><strong>Get familiar with the exam environment</strong>: practice using Windows, opening Jupyter Notebook, navigating with the command prompt (i.e., both the standard Windows command prompt as well as Anaconda Prompt), and setting working directories.</li>
<li><strong>Know how to zip and unzip files</strong> so you can upload or submit repositories without issues.</li>
<li><strong>Use and prepare cheatsheet</strong>: one PDF file, printed cheatsheets are not allowed.</li>
<li>The <strong>inspect mode in Edge is blocked</strong>. Please <strong>use Chrome</strong> (installed) and access the inspect mode there.</li>
<li><strong>File and code management</strong>:
<ul>
<li>You must not use network drives to store your data. Please choose a local folder such as <code>C:\Users\&lt;YOUR-U-NUMBER&gt;\Downloads</code>.</li>
<li>Organize downloaded files into separate folders (e.g., by question), to avoid confusion.</li>
<li>Revise code before submission to ensure it runs cleanly from top to bottom.</li>
<li>Do <strong>not</strong> include your name or student number anywhere in files, folders, or code (grading is anonymous).</li>
<li>Be comfortable opening <code>.py</code> and <code>.ipynb</code> files, as well as <code>.json</code>, <code>.csv</code> and <code>.txt</code> files.</li>
<li>Know how to set environment variables via <code>.env</code> files.</li>
</ul></li>
<li><strong>Finding working directories</strong>:
<ul>
<li>Be able to locate your working directory in all programs (Jupyter Notebook, VS Code, Explorer, Command Prompt, Anaconda Prompt).</li>
</ul></li>
<li><strong>Save time on exam day</strong>: before the exam officially starts, open the required software (e.g., Jupyter Notebook) and set working directories so you can begin immediately.</li>
</ul>
</section>
</section>
<section id="inspection" class="level1">
<h1>Inspection</h1>
<p>After the exams have been graded, you will have the opportunity to attend the exam inspection. The goals of this inspection are for you to (a) understand how your exam has been graded (i.e., per question), (b) learn from viewing an answer key to a particular question, and (c) verify the answer key has been applied consistently.</p>
<p>The date of the exam inspection will be communicated via Canvas. The review will take place in a computer room on campus.</p>
<section id="logging-in" class="level2">
<h2 class="anchored" data-anchor-id="logging-in">Logging in</h2>
<ul>
<li>Login to <a href="https://tiu.nu/testvision">TestVision</a> via SurfConext with your Tilburg University account.</li>
<li>Select <strong>show results</strong>.</li>
<li>Select the relevant exam and enter the password that will be shared with you in class.</li>
</ul>
</section>
<section id="inspect-your-exam" class="level2">
<h2 class="anchored" data-anchor-id="inspect-your-exam">Inspect your exam</h2>
<section id="get-an-overview-of-the-points-obtained" class="level3">
<h3 class="anchored" data-anchor-id="get-an-overview-of-the-points-obtained">1) Get an overview of the points obtained</h3>
<p>First, we advise you to get a global understanding of how you performed on the exam by checking the “question overview.”</p>
<p><img src="inspection1.png" class="img-fluid"></p>
<p>We advise you to zoom in on the questions for which you did not obtain total points.</p>
</section>
<section id="review-each-question" class="level3">
<h3 class="anchored" data-anchor-id="review-each-question">2) Review each question</h3>
<p>You can review the grading of each question by clicking on the question number.</p>
<ul>
<li>Check the points you have obtained for the question.</li>
</ul>
<p><img src="points.png" class="img-fluid"></p>
<ul>
<li><p>View the question and read your answer.</p></li>
<li><p>Check our feedback (mostly in writing) by clicking on ‘Feedback’. You can view the correct answer by clicking on ‘Response model’.</p></li>
</ul>
<p><img src="feedback.png" class="img-fluid"></p>
<p>Note that written feedback may not be available for all questions. In that case, compare your answer to the response model/answer key.</p>
</section>
<section id="ask-questions" class="level3">
<h3 class="anchored" data-anchor-id="ask-questions">3) Ask questions</h3>
<p>Would you like to ask how the answer key was applied in your case? Ask the instructor that is present during the inspection.</p>
</section>
<section id="file-a-written-request-for-review" class="level3">
<h3 class="anchored" data-anchor-id="file-a-written-request-for-review">4) File a written request for review</h3>
<p>Any unresolved questions? Then <strong>file a request for review</strong>.</p>
<ul>
<li>Do so for each question by entering a comment in the designated comment box on TestVision, which is located below each question.</li>
</ul>
<p><img src="commentbox.png" class="img-fluid"></p>
<ul>
<li>When adding a request for review, please <strong>briefly</strong> argue why you believe you deserve (more) points for the specific question. In your request, refer as much as possible to the answer key.</li>
</ul>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>